






BWise - Governance, Risk and Compliance Management

































Contact
For more information about our software solutions, please contact us.







Banking
BWises Governance, Risk, and Compliance (GRC) solutions are designed to cover the critical risk management aspects affecting the financial services industry.








IndustriesAirlinesAutomotiveBankingEnergy and UtilitiesChemicals




IndustriesInsuranceLeasingLife SciencesManufacturingServices













GRC Journey Web TV
Clarinda Dobbelaar interviews Ladd Muzzy, Principal at Nasdaq BWise, about how companies can build a Cyber Defense Program to face the ever-evolving risks.







Webinar
Register for the webinar Introducing the BWise Information Security Best-Practice Solution.








Integrated GRCA truly integrated GRC Software PlatformBWise GRC Platform
GovernanceFinancial GovernanceCorporate GovernanceIT GovernanceRisk ManagementBWise Risk ManagementOperational Risk ManagementEnterprise Risk ManagementBusiness Continuity ManagementRisk and Control AssessmentsVendor Risk ManagementInternal AuditBWise Internal AuditAudit AnalyticsCase Management
Internal ControlBWise Internal ControlSoft Control TestingContinuous Monitoring




Compliance ManagementBWise Compliance and Policy ManagementWaiver ManagementSegregation of Duties Regulatory Feeds
Information SecurityBWise Information SecurityData AnalyticsQuantitative Risk ManagementFrameworksCOBITUnified Compliance Framework (UCF)Laws and RegulationsBasel IIIBill 198Conflict MineralsDodd Frank ActFERCFCPAMore...













Contact
For more information about our software solutions, please contact us.







Support
Access the Online Service Desk








ServicesImplementation ServicesRapid Deployment SolutionsBWise Center of ExcellenceHosting ServicesMaintenance and Support




BWise Academy


















BWise® Internal Audit

Enterprise Governance, Risk Management and Compliance (GRC) Software

                Read more
                



.

.








BWise® Risk Management

Enterprise Governance, Risk Management and Compliance (GRC) Software

                Read more
                



.

.








BWise® Compliance Management

Enterprise Governance, Risk Management and Compliance (GRC) Software

                Read more
                



.

.








BWise® Internal Control

Enterprise Governance, Risk Management and Compliance (GRC) Software

                Read more
                



.

.








BWise® Information Security

Enterprise Governance, Risk Management and Compliance (GRC) Software

                Read more
                



.

.








Highlights
Webinar with KPMG - Leading practice for developing a strong risk culture

A robust risk culture is no longer a nice to have with many regulators now insisting on it. We hosted a joined webinar with KPMG LLP on July 31st to understand how to develop a strong risk culture inside your organization.More...

Nasdaq's BWise and KPMG Align to Provide Comprehensive GRC Solutions

KPMG  LLP and Nasdaq BWise offer an organization a proven solution for GRC, by combining their joint expertise.More...

GRC Journey Magazine

GRC Journey Magazine for Leading Risk Management, Audit, Internal Control and Compliance Professionals.More...

Recorded Webinar: BWise Information Security Best-Practice Solution

Request the recorded webinar to see Nasdaqs Pre-Configured Solution to Streamline Information Security Processes.More...

GRC Journey Web TV

Nasdaq BWise is the global leader in Governance, Risk and Compliance (GRC) Management software.More...










                Latest News
            




Latest News



			KPMG  LLP and Nasdaq BWise offer an organization a proven solution for GRC, by combining their joint expertise.
		








                GRC Journey Magazine
            




GRC Journey Magazine



			Read our latest GRC Journey Magazine
		








                Because GRC Is Already Hard Enough
            




Because GRC Is Already Hard Enough



			Nasdaq Introduces BWise 5.0: Designed to Support GRC Professionals in their Critical Mission Better than Ever Before.
		








                GRC Journey Web TV
            




GRC Journey Web TV



			Watch our videos about Governance, Risk and Compliance Management.
		





 


Choose your language:
DutchEnglishFrenchGermanPortuguese (BR)Spanish

 
Scroll up
















 


List of companies of Sweden - Wikipedia





















 






List of companies of Sweden

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search

This is a list of notable companies based in Sweden, grouped by their Industry Classification Benchmark sector. For further information on the types of business entities in this country and their abbreviations, see "Business entities in Sweden".



Contents


1 Basic materials
2 Conglomerates
3 Consumer goods
4 Financials
5 Health care
6 Industrials
7 Media
8 Oil & gas
9 Retail
10 Travel & leisure
11 Telecommunications
12 Technology
13 Utilities
14 References
15 See also



Basic materials[edit]

BillerudKorsnäs, paper
Boliden AB, mining
Holmen, paper
Höganäs AB, powdered metals
Kosta Glasbruk, glass
LKAB, mining
Nyby bruk, stainless steel, a part of Outokumpu
Orrefors glassworks, glass
Ovako, steel
SSAB, steel

Domnarvet, a part of SSAB


Stora Enso (Swedish-Finnish), paper
Svenska Cellulosa Aktiebolaget (SCA), paper
Södra, paper pulp, sawmills
Uddeholms AB, steel, a part of Voestalpine AG
Vida AB, sawmills

Conglomerates[edit]

Axel Johnson Group

Axel Johnson AB
Axfood
Nordstjernan


Grimaldi Industri AB
Stena Sphere

Consumer goods[edit]

AarhusKarlshamn (AAK), vegetable oils, fats
Abba Seafood, seafood
ABU Garcia, fishing reels, now part of Jarden corporation
Acne Studios, fashion
Arla Foods, dairy
Ballograf, ballpoint pens and pencils
Björn Borg, fashion
Brio, toys
Cheap Monday, clothing
Clavia, musical instruments
Cloetta, chocolate
Electrolux, appliances
Elfa International, shelving
Ellos, e-commerce
Esselte, office products, now a part of J.W. Childs Associates
Filippa K, clothing
Findus, frozen food, now owned by Lion Capital LLP
Fjällräven, outdoor clothing
Galvin Green, golf clothing
GB Glace, ice cream, now owned by Unilever
Haglöfs, outdoor equipment
Hagström, musical instruments
Hasselblad, cameras
Hestra, gloves
Husaberg AB, motorcycles
IsaDora, cosmetics
J.Lindeberg (JL), clothing
Jens of Sweden, defunct media players
Jofa, defunct sport equipment, now part of Reebok
Koenigsegg, automotive
Kopparbergs Brewery, brewery
Krönleins, brewery
Kungsörnen, food
Lantmännen, agriculture cooperative
Luxor, defunct home electronics, acquired by Nokia
Marabou, acquired by Kraft Foods
Monark, bicycle
Mora of Sweden, knives
Nobia, kitchen
Nudie Jeans, clothing
Odd Molly, clothing
Oriflame, cosmetics
Polarbröd, bread
PostNord, mail, logistics
Primus AB, portable cooking devices
Pripps, brewery, now part of Carlsberg Group
Pågen, bakery
Saab Automobile, automotive, now owned by NEVS
SIA Glace, ice cream
Silva compass, navigation equipment
Spendrups, brewery
Stiga, garden mowers, now part of Global Garden Products S.p.A
Swedish Match, tobacco
Thule, automotive
Urbanears, headphones
V&S Group, beverages
Volvo Cars, automotive, part of Geely Automobile
VSM Group, now part of SVP Worldwide
Wasabröd, bread, now part of Barilla Group
Wayne's Coffee, coffeehouse chain
WESC, clothing

Financials[edit]

Avanza, stock broker
Bure Equity, investments
Carnegie Investment Bank, financial services
Danir AB, investments
Forex Bank, currency exchange
Handelsbanken, bank
Ikano Bank, bank
Investment AB Kinnevik, investments
Investment AB Latour, investment
Investment AB Öresund, investment
Investor AB, investments
L E Lundbergföretagen, investments
Länsförsäkringar, financial services
Melker Schörling, investment
Nordea (Swedish-Finnish), financial services
OMX AB, financial services
Ratos, private equity
Resurs Bank, bank
Skandia, financial services
Skandinaviska Enskilda Banken (SEB), financial services

Skandinaviska Banken, defunct bank, merged into SEB
Stockholms Enskilda Bank, merged into SEB


Stockholm Stock Exchange, stock exchange, part of OMX AB
Swedbank (FöreningsSparbanken), bank

Föreningsbanken, defunct rural bank, merged into Swedbank


Trustly, online banking payments

Health care[edit]

3H Biomedical, bio tech
AstraZeneca (Swedish-British), pharmaceutical

Astra, defunct pharma now merged into AstraZeneca


Biacore, now a part of GE Healthcare
BioGaia, probiotic
Cederroth, personal health care
Diamyd Medical, research
Elekta, radiation therapy
Getinge Group, medical technology
Meda AB, pharmaceutical
Mölnlycke Health Care, medical device
Nobel Biocare (Swedish-Swiss), dental implants
Orexo, pharmaceutical
Phadia, blood test systems
Pharmacia, defunct pharma
Promessa Organic, eco-burial
Recipharm, pharmaceutical
Swedish Orphan Biovitrum, specialty healthcare

Industrials[edit]

Alfa Laval, heavy industry
Alfdex, industrial separators
AkzoNobel, paints, coatings
AP&T, metal forming machinery
Arcam, 3D printing
Asea Brown Boveri (ABB), robotics, automation

ASEA, defunct


Assa Abloy, locks
Atlas Copco, industrials
Atlet AB, trucks, now part of Nissan
Autoliv, automotive safety
BAE Systems AB, defence, part of Bae systems land and armaments
Bahco, now a part of Snap-on
Berg Propulsion, controllable pitch propellers
Bindomatic, office supplies
Bofors, arms
Boghammar Marin AB, shipyard
Bona AB, flooring
Camfil, air filtration
DeLaval, farm machines
Dockstavarvet, shipyard
Elanders, printing
ESAB, industrials, now a part of Colfax Corporation
Expander System Sweden AB, industrial machinery
Fagerhult Group, lighting
FKAB, ship design/construction
Flexlink, industrial automation
Gunnebo Security Group, security
Haldex, automotive parts
Hallberg-Rassy, sailing yachts
Hexagon, metrology
HIAB, lifts and cranes, now a part of Cargotec
Husqvarna, commercial tools

Jonsereds Fabrikers AB, now part of Husqvarna Group


Loomis, security
Mecel, consulting
Micromy, industrial coatings
Najad Yachts, sailing yachts
NCC AB, construction
NOHAB, defunct manufacturing
NorthStar, lead-acid batteries
Nyfors Teknologi AB, optical fiber equipment
Oskarshamn Shipyard
Peab, construction
Profoto, lighting
Saab, aerospace

Bofors, arms
Datasaab, computer division of Saab
Kockums Naval Solutions, shipyard


Sandvik, engineering
Scania AB, commercial automotive, now a part of Volkswagen Group

Vabis, part of Scania


Securitas AB, security
Securitas Direct, security
Semcon, consulting
Skanska, construction

Göinge Mekaniska AB, defunct steel buildings, merged into Skanska


SKF, mechanical parts
Sweco, consulting
Swegon, ventilation system
TetraPak, food packaging
Trelleborg AB, engineering
Volvo, industrial vehicles

Bolinder-Munktell, now a part of Volvo Construction Equipment


Wallenius Lines, shipping
Wise Group, consulting
ÅF, consulting
Öhlins, automotive parts

Media[edit]

AB Svensk Filmindustri, film production
Betsson, online gambling
Bonnier Group, media
LeoVegas, mobile gaming
Maratone Studios, music production
Metro International, media
Modern Times Group (MTG), digital entertainment
Paradox Entertainment, entertainment
TV4 AB, media
Sveriges Television, Swedish national public TV broadcaster
WG Film, film production
X5 Music Group, music recordings

Oil & gas[edit]

AGA, defunct natural gas, now part of Linde AG
Lundin Petroleum, oil
Nynas, oil

Retail[edit]

Åhléns, retail department stores
Clas Ohlson, hardware stores
Coop Norden, retail chain
Gekås, Swedish superstore
Hennes & Mauritz (H&M), retail clothing
Hästens, beds
ICA AB, retailing group
IKEA (founded in Sweden, but controlled by organisations based in the Netherlands)[1]
Lindex, fashion retailer
Nordiska Kompaniet, retail department stores
Onoff, retail chain defunct in 2011
SIBA AB, retail

Travel & leisure[edit]

Destination Gotland, ferry-line
Malmö Aviation, airline
Nextjet, regional airline
Nobina, public transport
Rederi AB Slite, defunct ferry-line
SAS Group (Swedish-Norwegian-Danish), airlines

Linjeflyg, defunct airline, acquired by SAS


Scandic Hotels, hotels
SJ AB, public transport
Stena Line, ferry-line

Telecommunications[edit]

Appear, mobility solutions
Aptilo Networks, mobile services
Bahnhof, internet service provider
Bredbandsbolaget, triple play services, now owned by Telenor
Columbitech, wireless security
Com Hem, triple play services
Doro, telecommunications products
Eniro, directory, search services
Ericsson, communication technology
Handheld Group, rugged computer
HMS Industrial Networks, industrial communications
Nanoradio, wireless semiconductors, now owned by Samsung
Neonode, touch technology
Symsoft, mobile services
Tele2, telecommunications

Comviq, merged into Tele2


TeliaSonera (Swedish-Finnish), mobile networks
Teracom, terrestrial broadcast
TerraNet AB, network
Transmode, network solutions
TrioAB, telecommunications

Technology[edit]

Acando, IT consulting
Acast, podcast streaming software
Avalanche Studios, video games
Axis Communications, network cameras acquired by Canon Inc.
Cision, software
Draim, games
EA Digital Illusions Creative Entertainment, video games
Elektron, synthesizers
ENEA, information technology
Fatshark, video games
Frictional Games, video games
IAR Systems, software
IFS AB, software
Illuminate Labs, video games lighting
IMINT Image Intelligence AB, software
Ingate, data security
Intertex, computer peripherals
Jeeves, software
Klarna, e-commerce
MachineGames, video games, part of ZeniMax Media
Mojang AB, video games, acquired by Microsoft
MySQL AB, acquired by Sun microsystems
Neogames, role-playing game publisher
Paradox Interactive, video games
Peltarion, software
ReadSoft, software
Remograph, software
SamLogic, software
Scalado, software
Seavus, software
Sector3 Studios, video games
Simogo, video games
Skygoblin, video games
Smart Eye, hardware and software
Soundcloud, online audio distribution
Spotify, streaming
Starbreeze Studios, video games
Syncron, software
Tarsier Studios, video games
Telelogic, software, part of IBM
Tieto (Swedish-Finnish), IT services
Tradedoubler, internet marketing
Massive Entertainment, video games, part of Ubisoft
WM-data, IT consulting

Utilities[edit]

European Spallation Source, research
Mälarenergi, power
Skellefteå Kraft, power
Studsvik, power
Swedish Space Corporation, space
Umeå Energi, power
Vattenfall, power

References[edit]



^ "IKEA: Flat-pack accounting". The Economist. 11 May 2006. Retrieved 5 January 2012. 



See also[edit]

List of banks in Sweden
List of Swedish entrepreneurs
List of Swedish government enterprises
List of Swedish people by net worth
List of video game companies of Sweden
Confederation of Swedish Enterprise
Economy of Sweden







v
t
e


List of companies of Europe



Sovereign states



Albania
Andorra
Armenia
Austria
Azerbaijan
Belarus
Belgium
Bosnia and Herzegovina
Bulgaria
Croatia
Cyprus
Czech Republic
Denmark
Estonia
Finland
France
Georgia
Germany
Greece
Hungary
Iceland
Ireland

Italy
Kazakhstan
Latvia
Liechtenstein
Lithuania
Luxembourg
Macedonia
Malta
Moldova
Monaco
Montenegro
Netherlands
Norway
Poland
Portugal
Romania
Russia
San Marino
Serbia
Slovakia
Slovenia
Spain
Sweden
Switzerland
Turkey
Ukraine
United Kingdom
Vatican City





States with limited
recognition



Abkhazia
Kosovo
Nagorno-Karabakh
Northern Cyprus
South Ossetia
Transnistria





Dependencies and
other entities



Åland
Faroe Islands
Gibraltar
Guernsey
Isle of Man
Jersey
Svalbard





Other entities



European Union










 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=List_of_companies_of_Sweden&oldid=778175428"					
Categories: Companies of SwedenLists of companies by countryLists of companies of Sweden 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



Languages


DeutschEspañolFrançaisNorsk bokmålPortuguêsRomânăРусскийУкраїнська 
Edit links 





 This page was last edited on 1 May 2017, at 15:52.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 









Matrix multiplication - Wikipedia






















 






Matrix multiplication

From Wikipedia, the free encyclopedia


					Jump to:					navigation, 					search





Multiplication of two matrices illustrated with a 3×2 and a 2×4 matrix with arbitrary symbols


In mathematics, matrix multiplication or the matrix product is a binary operation that produces a matrix from two matrices. The definition is motivated by linear equations and linear transformations on vectors, which have numerous applications in applied mathematics, physics, and engineering.[1][2] In more detail, if A is an n × m matrix and B is an m × p matrix, their matrix product AB is an n × p matrix, in which the m entries across a row of A are multiplied with the m entries down a columns of B and summed to produce an entry of AB. When two linear transformations are represented by matrices, then the matrix product represents the composition of the two transformations.
The matrix product is not commutative in general, although it is associative and is distributive over matrix addition. The identity element of the matrix product is the identity matrix (analogous to multiplying numbers by 1), and a square matrix may have an inverse matrix (analogous to the multiplicative inverse of a number). Determinant multiplicativity applies to the matrix product. The matrix product is also important for matrix groups, and the theory of group representations and irreps.
Computing matrix products is both a central operation in many numerical algorithms and potentially time consuming, making it one of the most well-studied problems in numerical computing. Various algorithms have been devised for computing C = AB, especially for large matrices.



Contents


1 Notation
2 Matrix product (two matrices)

2.1 General definition of the matrix product
2.2 Illustration
2.3 Examples of matrix products

2.3.1 Row vector and column vector
2.3.2 Square matrix and column vector
2.3.3 Square matrices
2.3.4 Row vector, square matrix, and column vector
2.3.5 Rectangular matrices


2.4 Properties of the matrix product (two matrices)

2.4.1 All matrices
2.4.2 Square matrices only




3 Matrix product (any number of matrices in the product)

3.1 Properties of the matrix product (any number of matrices in the product)
3.2 Examples of chain multiplication


4 Operations derived from the matrix product

4.1 Powers of matrices


5 Applications of the matrix product

5.1 Linear transformations
5.2 Linear systems of equations
5.3 Group theory and representation theory


6 The inner and outer products

6.1 Inner product
6.2 Outer product


7 Algorithms for efficient matrix multiplication

7.1 Parallel matrix multiplication
7.2 Communication-avoiding and distributed algorithms


8 Other forms of multiplication
9 See also
10 Notes
11 References
12 External links



Notation[edit]
This article will use the following notational conventions: matrices are represented by capital letters in bold, e.g. A, vectors in lowercase bold, e.g. a, and entries of vectors and matrices are italic (since they are numbers from a field), e.g. A and a. Index notation is often the clearest way to express definitions, and is used as standard in the literature. The i, j entry of matrix A is indicated by (A)ij or Aij, whereas a numerical label (not matrix entries) on a collection of matrices is subscripted only, e.g. A1, A2, etc.
Matrix product (two matrices)[edit]
Assume two matrices are to be multiplied (the generalization to any number is discussed below).
General definition of the matrix product[edit]




Arithmetic process of multiplying numbers (solid lines) in row i in matrix A and column j in matrix B, then adding the terms (dashed lines) to obtain entry ij in the final matrix.


If A is an n × m matrix and B is an m × p matrix,






A

=


(




A

11





A

12




⋯



A

1
m







A

21





A

22




⋯



A

2
m






⋮


⋮


⋱


⋮





A

n
1





A

n
2




⋯



A

n
m





)


,


B

=


(




B

11





B

12




⋯



B

1
p







B

21





B

22




⋯



B

2
p






⋮


⋮


⋱


⋮





B

m
1





B

m
2




⋯



B

m
p





)




{\displaystyle \mathbf {A} ={\begin{pmatrix}A_{11}&A_{12}&\cdots &A_{1m}\\A_{21}&A_{22}&\cdots &A_{2m}\\\vdots &\vdots &\ddots &\vdots \\A_{n1}&A_{n2}&\cdots &A_{nm}\\\end{pmatrix}},\quad \mathbf {B} ={\begin{pmatrix}B_{11}&B_{12}&\cdots &B_{1p}\\B_{21}&B_{22}&\cdots &B_{2p}\\\vdots &\vdots &\ddots &\vdots \\B_{m1}&B_{m2}&\cdots &B_{mp}\\\end{pmatrix}}}



the matrix product AB (denoted without multiplication signs or dots) is defined to be the n × p matrix[3][4][5][6]






A


B

=


(





(

A
B

)


11






(

A
B

)


12




⋯




(

A
B

)


1
p








(

A
B

)


21






(

A
B

)


22




⋯




(

A
B

)


2
p






⋮


⋮


⋱


⋮






(

A
B

)


n
1






(

A
B

)


n
2




⋯




(

A
B

)


n
p





)




{\displaystyle \mathbf {A} \mathbf {B} ={\begin{pmatrix}\left(\mathbf {AB} \right)_{11}&\left(\mathbf {AB} \right)_{12}&\cdots &\left(\mathbf {AB} \right)_{1p}\\\left(\mathbf {AB} \right)_{21}&\left(\mathbf {AB} \right)_{22}&\cdots &\left(\mathbf {AB} \right)_{2p}\\\vdots &\vdots &\ddots &\vdots \\\left(\mathbf {AB} \right)_{n1}&\left(\mathbf {AB} \right)_{n2}&\cdots &\left(\mathbf {AB} \right)_{np}\\\end{pmatrix}}}



where each i, j entry is given by multiplying the entries Aik (across row i of A) by the entries Bkj (down column j of B), for k = 1, 2, ..., m, and summing the results over k:





(

A


B


)

i
j


=

∑

k
=
1


m



A

i
k



B

k
j



.


{\displaystyle (\mathbf {A} \mathbf {B} )_{ij}=\sum _{k=1}^{m}A_{ik}B_{kj}\,.}



Thus the product AB is defined only if the number of columns in A is equal to the number of rows in B, in this case m. Each entry may be computed one at a time. Sometimes, the summation convention is used as it is understood to sum over the repeated index k. To prevent any ambiguity, this convention will not be used in the article.
Usually the entries are numbers or expressions, but can even be matrices themselves (see block matrix). The matrix product can still be calculated exactly the same way. See below for details on how the matrix product can be calculated in terms of blocks taking the forms of rows and columns.
Illustration[edit]

The figure to the right illustrates diagrammatically the product of two matrices A and B, showing how each intersection in the product matrix corresponds to a row of A and a column of B.








[





a

11







a

12







⋅


⋅






a

31







a

32







⋅


⋅



]


4
×
2

 matrix







[



⋅




b

12







b

13







⋅




b

22







b

23






]


2
×
3

 matrix




=



[



⋅



x

12





x

13






⋅


⋅


⋅




⋅



x

32





x

33






⋅


⋅


⋅



]


4
×
3

 matrix






{\displaystyle {\overset {4\times 2{\text{ matrix}}}{\begin{bmatrix}{a_{11}}&{a_{12}}\\\cdot &\cdot \\{a_{31}}&{a_{32}}\\\cdot &\cdot \\\end{bmatrix}}}{\overset {2\times 3{\text{ matrix}}}{\begin{bmatrix}\cdot &{b_{12}}&{b_{13}}\\\cdot &{b_{22}}&{b_{23}}\\\end{bmatrix}}}={\overset {4\times 3{\text{ matrix}}}{\begin{bmatrix}\cdot &x_{12}&x_{13}\\\cdot &\cdot &\cdot \\\cdot &x_{32}&x_{33}\\\cdot &\cdot &\cdot \\\end{bmatrix}}}}



The values at the intersections marked with circles are:










x

12





=


a

11





b

12



+


a

12





b

22








x

33





=


a

31





b

13



+


a

32





b

23









{\displaystyle {\begin{aligned}x_{12}&={a_{11}}{b_{12}}+{a_{12}}{b_{22}}\\x_{33}&={a_{31}}{b_{13}}+{a_{32}}{b_{23}}\end{aligned}}}



Examples of matrix products[edit]
Row vector and column vector[edit]
If






A

=


(



a


b


c



)



,


B

=


(



x




y




z



)



,


{\displaystyle \mathbf {A} ={\begin{pmatrix}a&b&c\end{pmatrix}}\,,\quad \mathbf {B} ={\begin{pmatrix}x\\y\\z\end{pmatrix}}\,,}



their matrix products are:






A
B

=


(



a


b


c



)




(



x




y




z



)


=
a
x
+
b
y
+
c
z

,


{\displaystyle \mathbf {AB} ={\begin{pmatrix}a&b&c\end{pmatrix}}{\begin{pmatrix}x\\y\\z\end{pmatrix}}=ax+by+cz\,,}



and






B
A

=


(



x




y




z



)




(



a


b


c



)


=


(



x
a


x
b


x
c




y
a


y
b


y
c




z
a


z
b


z
c



)



.


{\displaystyle \mathbf {BA} ={\begin{pmatrix}x\\y\\z\end{pmatrix}}{\begin{pmatrix}a&b&c\end{pmatrix}}={\begin{pmatrix}xa&xb&xc\\ya&yb&yc\\za&zb&zc\end{pmatrix}}\,.}



Note AB and BA are two different matrices: the first is a 1 × 1 matrix while the second is a 3 × 3 matrix. Such expressions occur for real-valued Euclidean vectors in Cartesian coordinates, displayed as row and column matrices, in which case AB is the matrix form of their dot product, while BA the matrix form of their dyadic or tensor product.
Square matrix and column vector[edit]
If






A

=


(



a


b


c




p


q


r




u


v


w



)


,


B

=


(



x




y




z



)



,


{\displaystyle \mathbf {A} ={\begin{pmatrix}a&b&c\\p&q&r\\u&v&w\end{pmatrix}},\quad \mathbf {B} ={\begin{pmatrix}x\\y\\z\end{pmatrix}}\,,}



their matrix product is:






A
B

=


(



a


b


c




p


q


r




u


v


w



)




(



x




y




z



)


=


(



a
x
+
b
y
+
c
z




p
x
+
q
y
+
r
z




u
x
+
v
y
+
w
z



)



,


{\displaystyle \mathbf {AB} ={\begin{pmatrix}a&b&c\\p&q&r\\u&v&w\end{pmatrix}}{\begin{pmatrix}x\\y\\z\end{pmatrix}}={\begin{pmatrix}ax+by+cz\\px+qy+rz\\ux+vy+wz\end{pmatrix}}\,,}



however BA is not defined.
The product of a square matrix multiplied by a column matrix arises naturally in linear algebra; for solving linear equations and representing linear transformations. By choosing a, b, c, p, q, r, u, v, w in A appropriately, A can represent a variety of transformations such as rotations, scaling and reflections, shears, of a geometric shape in space.
Square matrices[edit]
If






A

=


(



a


b


c




p


q


r




u


v


w



)


,


B

=


(



α


β


γ




λ


μ


ν




ρ


σ


τ



)



,


{\displaystyle \mathbf {A} ={\begin{pmatrix}a&b&c\\p&q&r\\u&v&w\end{pmatrix}},\quad \mathbf {B} ={\begin{pmatrix}\alpha &\beta &\gamma \\\lambda &\mu &\nu \\\rho &\sigma &\tau \\\end{pmatrix}}\,,}



their matrix products are:






A
B

=


(



a


b


c




p


q


r




u


v


w



)




(



α


β


γ




λ


μ


ν




ρ


σ


τ



)


=


(



a
α
+
b
λ
+
c
ρ


a
β
+
b
μ
+
c
σ


a
γ
+
b
ν
+
c
τ




p
α
+
q
λ
+
r
ρ


p
β
+
q
μ
+
r
σ


p
γ
+
q
ν
+
r
τ




u
α
+
v
λ
+
w
ρ


u
β
+
v
μ
+
w
σ


u
γ
+
v
ν
+
w
τ



)



,


{\displaystyle \mathbf {AB} ={\begin{pmatrix}a&b&c\\p&q&r\\u&v&w\end{pmatrix}}{\begin{pmatrix}\alpha &\beta &\gamma \\\lambda &\mu &\nu \\\rho &\sigma &\tau \\\end{pmatrix}}={\begin{pmatrix}a\alpha +b\lambda +c\rho &a\beta +b\mu +c\sigma &a\gamma +b\nu +c\tau \\p\alpha +q\lambda +r\rho &p\beta +q\mu +r\sigma &p\gamma +q\nu +r\tau \\u\alpha +v\lambda +w\rho &u\beta +v\mu +w\sigma &u\gamma +v\nu +w\tau \end{pmatrix}}\,,}



and






B
A

=


(



α


β


γ




λ


μ


ν




ρ


σ


τ



)




(



a


b


c




p


q


r




u


v


w



)


=


(



α
a
+
β
p
+
γ
u


α
b
+
β
q
+
γ
v


α
c
+
β
r
+
γ
w




λ
a
+
μ
p
+
ν
u


λ
b
+
μ
q
+
ν
v


λ
c
+
μ
r
+
ν
w




ρ
a
+
σ
p
+
τ
u


ρ
b
+
σ
q
+
τ
v


ρ
c
+
σ
r
+
τ
w



)



.


{\displaystyle \mathbf {BA} ={\begin{pmatrix}\alpha &\beta &\gamma \\\lambda &\mu &\nu \\\rho &\sigma &\tau \\\end{pmatrix}}{\begin{pmatrix}a&b&c\\p&q&r\\u&v&w\end{pmatrix}}={\begin{pmatrix}\alpha a+\beta p+\gamma u&\alpha b+\beta q+\gamma v&\alpha c+\beta r+\gamma w\\\lambda a+\mu p+\nu u&\lambda b+\mu q+\nu v&\lambda c+\mu r+\nu w\\\rho a+\sigma p+\tau u&\rho b+\sigma q+\tau v&\rho c+\sigma r+\tau w\end{pmatrix}}\,.}



In this case, both products AB and BA are defined, and the entries show that AB and BA are not equal in general. Multiplying square matrices which represent linear transformations corresponds to the composite transformation (see below for details).
Row vector, square matrix, and column vector[edit]
If






A

=


(



a


b


c



)



,


B

=


(



α


β


γ




λ


μ


ν




ρ


σ


τ



)



,


C

=


(



x




y




z



)



,


{\displaystyle \mathbf {A} ={\begin{pmatrix}a&b&c\end{pmatrix}}\,,\quad \mathbf {B} ={\begin{pmatrix}\alpha &\beta &\gamma \\\lambda &\mu &\nu \\\rho &\sigma &\tau \\\end{pmatrix}}\,,\quad \mathbf {C} ={\begin{pmatrix}x\\y\\z\end{pmatrix}}\,,}



their matrix product is:










A
B
C




=


(



a


b


c



)



[


(



α


β


γ




λ


μ


ν




ρ


σ


τ



)




(



x




y




z



)


]

=

[


(



a


b


c



)




(



α


β


γ




λ


μ


ν




ρ


σ


τ



)


]



(



x




y




z



)








=


(



a


b


c



)




(



α
x
+
β
y
+
γ
z




λ
x
+
μ
y
+
ν
z




ρ
x
+
σ
y
+
τ
z



)


=


(



a
α
+
b
λ
+
c
ρ


a
β
+
b
μ
+
c
σ


a
γ
+
b
ν
+
c
τ



)




(



x




y




z



)








=
a
α
x
+
b
λ
x
+
c
ρ
x
+
a
β
y
+
b
μ
y
+
c
σ
y
+
a
γ
z
+
b
ν
z
+
c
τ
z

,






{\displaystyle {\begin{aligned}\mathbf {ABC} &={\begin{pmatrix}a&b&c\end{pmatrix}}\left[{\begin{pmatrix}\alpha &\beta &\gamma \\\lambda &\mu &\nu \\\rho &\sigma &\tau \\\end{pmatrix}}{\begin{pmatrix}x\\y\\z\end{pmatrix}}\right]=\left[{\begin{pmatrix}a&b&c\end{pmatrix}}{\begin{pmatrix}\alpha &\beta &\gamma \\\lambda &\mu &\nu \\\rho &\sigma &\tau \\\end{pmatrix}}\right]{\begin{pmatrix}x\\y\\z\end{pmatrix}}\\&={\begin{pmatrix}a&b&c\end{pmatrix}}{\begin{pmatrix}\alpha x+\beta y+\gamma z\\\lambda x+\mu y+\nu z\\\rho x+\sigma y+\tau z\\\end{pmatrix}}={\begin{pmatrix}a\alpha +b\lambda +c\rho &a\beta +b\mu +c\sigma &a\gamma +b\nu +c\tau \end{pmatrix}}{\begin{pmatrix}x\\y\\z\end{pmatrix}}\\&=a\alpha x+b\lambda x+c\rho x+a\beta y+b\mu y+c\sigma y+a\gamma z+b\nu z+c\tau z\,,\end{aligned}}}



however CBA is not defined. Note that A(BC) = (AB)C, this is one of many general properties listed below. Expressions of the form ABC occur when calculating the inner product of two vectors displayed as row and column vectors in an arbitrary coordinate system, and the metric tensor in these coordinates written as the square matrix.
Rectangular matrices[edit]
If






A

=


(



a


b


c




x


y


z



)



,


B

=


(



α


ρ




β


σ




γ


τ



)



,


{\displaystyle \mathbf {A} ={\begin{pmatrix}a&b&c\\x&y&z\end{pmatrix}}\,,\quad \mathbf {B} ={\begin{pmatrix}\alpha &\rho \\\beta &\sigma \\\gamma &\tau \\\end{pmatrix}}\,,}



their matrix products are:






A


B

=


(



a


b


c




x


y


z



)




(



α


ρ




β


σ




γ


τ



)


=


(



a
α
+
b
β
+
c
γ


a
ρ
+
b
σ
+
c
τ




x
α
+
y
β
+
z
γ


x
ρ
+
y
σ
+
z
τ



)



,


{\displaystyle \mathbf {A} \mathbf {B} ={\begin{pmatrix}a&b&c\\x&y&z\end{pmatrix}}{\begin{pmatrix}\alpha &\rho \\\beta &\sigma \\\gamma &\tau \\\end{pmatrix}}={\begin{pmatrix}a\alpha +b\beta +c\gamma &a\rho +b\sigma +c\tau \\x\alpha +y\beta +z\gamma &x\rho +y\sigma +z\tau \\\end{pmatrix}}\,,}



and






B


A

=


(



α


ρ




β


σ




γ


τ



)




(



a


b


c




x


y


z



)


=


(



α
a
+
ρ
x


α
b
+
ρ
y


α
c
+
ρ
z




β
a
+
σ
x


β
b
+
σ
y


β
c
+
σ
z




γ
a
+
τ
x


γ
b
+
τ
y


γ
c
+
τ
z



)



.


{\displaystyle \mathbf {B} \mathbf {A} ={\begin{pmatrix}\alpha &\rho \\\beta &\sigma \\\gamma &\tau \\\end{pmatrix}}{\begin{pmatrix}a&b&c\\x&y&z\end{pmatrix}}={\begin{pmatrix}\alpha a+\rho x&\alpha b+\rho y&\alpha c+\rho z\\\beta a+\sigma x&\beta b+\sigma y&\beta c+\sigma z\\\gamma a+\tau x&\gamma b+\tau y&\gamma c+\tau z\end{pmatrix}}\,.}



Properties of the matrix product (two matrices)[edit]
Analogous to numbers (elements of a field), matrices satisfy the following general properties, although there is one subtlety, due to the nature of matrix multiplication.[7][8]
All matrices[edit]


Not commutative:
In general:






A


B

≠

B


A



{\displaystyle \mathbf {A} \mathbf {B} \neq \mathbf {B} \mathbf {A} }



because AB and BA may not be simultaneously defined, and even if they are they may still not be equal. This is contrary to ordinary multiplication of numbers. To specify the ordering of matrix multiplication in words; "pre-multiply (or left multiply) A by B" means BA, while "post-multiply (or right multiply) A by C" means AC. As long as the entries of the matrix come from a ring that has an identity, and n > 1 there is a pair of n × n noncommuting matrices over the ring. A notable exception is that the identity matrix (or any scalar multiple of it) commutes with every square matrix.
In index notation:






∑

k



A

i
k



B

k
j


≠

∑

k



B

i
k



A

k
j




{\displaystyle \sum _{k}A_{ik}B_{kj}\neq \sum _{k}B_{ik}A_{kj}}




Distributive over matrix addition:
Left distributivity:






A

(

B

+

C

)
=

A
B

+

A
C



{\displaystyle \mathbf {A} (\mathbf {B} +\mathbf {C} )=\mathbf {AB} +\mathbf {AC} }



Right distributivity:





(

A

+

B

)

C

=

A
C

+

B
C



{\displaystyle (\mathbf {A} +\mathbf {B} )\mathbf {C} =\mathbf {AC} +\mathbf {BC} }



In index notation, these are respectively:






∑

k



A

i
k


(

B

k
j


+

C

k
j


)
=

∑

k



A

i
k



B

k
j


+

∑

k



A

i
k



C

k
j




{\displaystyle \sum _{k}A_{ik}(B_{kj}+C_{kj})=\sum _{k}A_{ik}B_{kj}+\sum _{k}A_{ik}C_{kj}}







∑

k


(

A

i
k


+

B

i
k


)

C

k
j


=

∑

k



A

i
k



C

k
j


+

∑

k



B

i
k



C

k
j




{\displaystyle \sum _{k}(A_{ik}+B_{ik})C_{kj}=\sum _{k}A_{ik}C_{kj}+\sum _{k}B_{ik}C_{kj}}




Scalar multiplication is compatible with matrix multiplication:





λ
(

A
B

)
=
(
λ

A

)

B



{\displaystyle \lambda (\mathbf {AB} )=(\lambda \mathbf {A} )\mathbf {B} }

 and 



(

A


B

)
λ
=

A

(

B

λ
)


{\displaystyle (\mathbf {A} \mathbf {B} )\lambda =\mathbf {A} (\mathbf {B} \lambda )}



where λ is a scalar. If the entries of the matrix are real or complex numbers (or from any other commutative ring), then all four quantities are equal. More generally, all four are equal if λ belongs to the center of the ring of entries of the matrix, because in this case λX = Xλ for all matrices X. In index notation, these are respectively:





λ

∑

k


(

A

i
k



B

k
j


)
=

∑

k


(
λ

A

i
k


)

B

k
j


=

∑

k



A

i
k


(
λ

B

k
j


)


{\displaystyle \lambda \sum _{k}(A_{ik}B_{kj})=\sum _{k}(\lambda A_{ik})B_{kj}=\sum _{k}A_{ik}(\lambda B_{kj})}







∑

k


(

A

i
k



B

k
j


)
λ
=

∑

k


(

A

i
k


λ
)

B

k
j


=

∑

k



A

i
k


(

B

k
j


λ
)


{\displaystyle \sum _{k}(A_{ik}B_{kj})\lambda =\sum _{k}(A_{ik}\lambda )B_{kj}=\sum _{k}A_{ik}(B_{kj}\lambda )}




Transpose:





(

A
B


)


T



=


B



T





A



T





{\displaystyle (\mathbf {AB} )^{\mathrm {T} }=\mathbf {B} ^{\mathrm {T} }\mathbf {A} ^{\mathrm {T} }}



where T denotes the transpose, the interchange of row i with column i in a matrix. This identity holds for any matrices over a commutative ring, but not for all rings in general. Note that A and B are reversed.
In index notation:











[
(

A
B


)


T



]


i
j





=


(

A
B

)


j
i








=

∑

k




(

A

)


j
k




(

B

)


k
i








=

∑

k




(


A



T



)


k
j




(


B



T



)


i
k








=

∑

k




(


B



T



)


i
k




(


A



T



)


k
j








=


[

(


B



T



)


(


A



T



)

]


i
j








{\displaystyle {\begin{aligned}\left[(\mathbf {AB} )^{\mathrm {T} }\right]_{ij}&=\left(\mathbf {AB} \right)_{ji}\\&=\sum _{k}\left(\mathbf {A} \right)_{jk}\left(\mathbf {B} \right)_{ki}\\&=\sum _{k}\left(\mathbf {A} ^{\mathrm {T} }\right)_{kj}\left(\mathbf {B} ^{\mathrm {T} }\right)_{ik}\\&=\sum _{k}\left(\mathbf {B} ^{\mathrm {T} }\right)_{ik}\left(\mathbf {A} ^{\mathrm {T} }\right)_{kj}\\&=\left[\left(\mathbf {B} ^{\mathrm {T} }\right)\left(\mathbf {A} ^{\mathrm {T} }\right)\right]_{ij}\end{aligned}}}




Complex conjugate:
If A and B have complex entries, then





(

A
B


)

∗


=


A


∗




B


∗




{\displaystyle (\mathbf {AB} )^{*}=\mathbf {A} ^{*}\mathbf {B} ^{*}}



where * denotes the entry-wise complex conjugate of a matrix.
In index notation:











[
(

A
B


)

∗


]


i
j





=


[

∑

k




(

A

)


i
k




(

B

)


k
j


]


∗








=

∑

k




(

A

)


i
k


∗




(

B

)


k
j


∗








=

∑

k




(


A


∗


)


i
k




(


B


∗


)


k
j








=


(


A


∗




B


∗


)


i
j








{\displaystyle {\begin{aligned}\left[(\mathbf {AB} )^{*}\right]_{ij}&=\left[\sum _{k}\left(\mathbf {A} \right)_{ik}\left(\mathbf {B} \right)_{kj}\right]^{*}\\&=\sum _{k}\left(\mathbf {A} \right)_{ik}^{*}\left(\mathbf {B} \right)_{kj}^{*}\\&=\sum _{k}\left(\mathbf {A} ^{*}\right)_{ik}\left(\mathbf {B} ^{*}\right)_{kj}\\&=\left(\mathbf {A} ^{*}\mathbf {B} ^{*}\right)_{ij}\end{aligned}}}




Conjugate transpose:
If A and B have complex entries, then





(

A
B


)

†


=


B


†




A


†




{\displaystyle (\mathbf {AB} )^{\dagger }=\mathbf {B} ^{\dagger }\mathbf {A} ^{\dagger }}



where † denotes the Conjugate transpose of a matrix (complex conjugate and transposed).
In index notation:











[
(

A
B


)

†


]


i
j





=


[


(

A
B

)


∗


]


j
i








=

∑

k




(


A


∗


)


j
k




(


B


∗


)


k
i








=

∑

k




(


A


†


)


k
j




(


B


†


)


i
k








=

∑

k




(


B


†


)


i
k




(


A


†


)


k
j








=


[

(


B


†


)


(


A


†


)

]


i
j








{\displaystyle {\begin{aligned}\left[(\mathbf {AB} )^{\dagger }\right]_{ij}&=\left[\left(\mathbf {AB} \right)^{*}\right]_{ji}\\&=\sum _{k}\left(\mathbf {A} ^{*}\right)_{jk}\left(\mathbf {B} ^{*}\right)_{ki}\\&=\sum _{k}\left(\mathbf {A} ^{\dagger }\right)_{kj}\left(\mathbf {B} ^{\dagger }\right)_{ik}\\&=\sum _{k}\left(\mathbf {B} ^{\dagger }\right)_{ik}\left(\mathbf {A} ^{\dagger }\right)_{kj}\\&=\left[\left(\mathbf {B} ^{\dagger }\right)\left(\mathbf {A} ^{\dagger }\right)\right]_{ij}\end{aligned}}}




Traces:
The trace of a product AB is independent of the order of A and B:






t
r

(

A
B

)
=

t
r

(

B
A

)


{\displaystyle \mathrm {tr} (\mathbf {AB} )=\mathrm {tr} (\mathbf {BA} )}



In index notation:










t
r

(

A
B

)



=

∑

i



∑

k



A

i
k



B

k
i








=

∑

k



∑

i



B

k
i



A

i
k








=

t
r

(

B
A

)






{\displaystyle {\begin{aligned}\mathrm {tr} (\mathbf {AB} )&=\sum _{i}\sum _{k}A_{ik}B_{ki}\\&=\sum _{k}\sum _{i}B_{ki}A_{ik}\\&=\mathrm {tr} (\mathbf {BA} )\end{aligned}}}






For extensive details on differentials and derivatives of products of matrix functions, see matrix calculus.
Square matrices only[edit]
Main article: square matrix


Identity element:
If A is a square matrix, then






A
I

=

I
A

=

A



{\displaystyle \mathbf {AI} =\mathbf {IA} =\mathbf {A} }



where I is the identity matrix of the same order.
Inverse matrix:
If A is a square matrix, there may be an inverse matrix A−1 of A such that






A



A


−
1


=


A


−
1



A

=

I



{\displaystyle \mathbf {A} \mathbf {A} ^{-1}=\mathbf {A} ^{-1}\mathbf {A} =\mathbf {I} }



If this property holds then A is an invertible matrix, if not A is a singular matrix. Moreover,





(

A
B


)


−
1



=


B



−
1





A



−
1





{\displaystyle (\mathbf {AB} )^{\mathrm {-1} }=\mathbf {B} ^{\mathrm {-1} }\mathbf {A} ^{\mathrm {-1} }}




Determinants:
When a determinant of a matrix is defined (i.e., when the underlying ring is commutative), if A and B are square matrices of the same order, the determinant of their product AB equals the product of their determinants:





det
(

A
B

)
=
det
(

A

)
det
(

B

)


{\displaystyle \det(\mathbf {AB} )=\det(\mathbf {A} )\det(\mathbf {B} )}



Since det(A) and det(B) are elements of the said commutative ring, det(A)det(B) = det(B)det(A), and so det(AB) = det(BA), even when AB ≠ BA.


Matrix product (any number of matrices in the product)[edit]
Main article: Matrix chain multiplication
Matrix multiplication can be extended to the case of more than two matrices, provided that for each sequential pair, their dimensions match.
The product of n matrices A1, A2, ..., An with sizes s0 × s1, s1 × s2, ..., sn − 1 × sn (where s0, s1, s2, ..., sn are all simply positive integers and the subscripts are labels corresponding to the matrices, nothing more), is the s0 × sn matrix:






∏

i
=
1


n




A


i


=


A


1




A


2


⋯


A


n



.


{\displaystyle \prod _{i=1}^{n}\mathbf {A} _{i}=\mathbf {A} _{1}\mathbf {A} _{2}\cdots \mathbf {A} _{n}\,.}



In index notation:







(


A


1




A


2


⋯


A


n


)



i

0



i

n




=

∑


i

1


=
1



s

1





∑


i

2


=
1



s

2




⋯

∑


i

n
−
1


=
1



s

n
−
1






(


A


1


)



i

0



i

1






(


A


2


)



i

1



i

2






(


A


3


)



i

2



i

3




⋯


(


A


n
−
1


)



i

n
−
2



i

n
−
1






(


A


n


)



i

n
−
1



i

n






{\displaystyle \left(\mathbf {A} _{1}\mathbf {A} _{2}\cdots \mathbf {A} _{n}\right)_{i_{0}i_{n}}=\sum _{i_{1}=1}^{s_{1}}\sum _{i_{2}=1}^{s_{2}}\cdots \sum _{i_{n-1}=1}^{s_{n-1}}\left(\mathbf {A} _{1}\right)_{i_{0}i_{1}}\left(\mathbf {A} _{2}\right)_{i_{1}i_{2}}\left(\mathbf {A} _{3}\right)_{i_{2}i_{3}}\cdots \left(\mathbf {A} _{n-1}\right)_{i_{n-2}i_{n-1}}\left(\mathbf {A} _{n}\right)_{i_{n-1}i_{n}}}



Properties of the matrix product (any number of matrices in the product)[edit]
The same properties will hold, as long as the ordering of matrices is not changed. Some of the previous properties for more than two matrices generalize as follows.


Associative:

The matrix product is associative. If three matrices A, B, and C are respectively m × p, p × q, and q × r matrices, then there are two ways of grouping them without changing their order, and






A
B
C

=

A

(

B
C

)
=
(

A
B

)

C



{\displaystyle \mathbf {ABC} =\mathbf {A} (\mathbf {BC} )=(\mathbf {AB} )\mathbf {C} }



is an m × r matrix.

If four matrices A, B, C, and D are respectively m × p, p × q, q × r, and r × s matrices, then there are five ways of grouping them without changing their order, and






A
B
C
D

=
(
(

A
B

)

C

)

D

=
(

A

(

B
C

)
)

D

=

A

(
(

B
C

)

D

)
=

A

(

B

(

C
D

)
)
=
(

A
B

)
(

C
D

)


{\displaystyle \mathbf {ABCD} =((\mathbf {AB} )\mathbf {C} )\mathbf {D} =(\mathbf {A} (\mathbf {BC} ))\mathbf {D} =\mathbf {A} ((\mathbf {BC} )\mathbf {D} )=\mathbf {A} (\mathbf {B} (\mathbf {CD} ))=(\mathbf {AB} )(\mathbf {CD} )}



is an m × s matrix.

In general, the number of possible ways of grouping n matrices for multiplication is equal to the (n − 1)th Catalan number
Trace:
The trace of a product of n matrices A1, A2, ..., An is invariant under cyclic permutations of the matrices in the product:






t
r

(


A


1




A


2




A


3


…


A


n
−
2




A


n
−
1




A


n


)
=

t
r

(


A


2




A


3




A


4


…


A


n
−
1




A


n




A


1


)
=

t
r

(


A


3




A


4




A


5


…


A


n




A


1




A


2


)
=
…


{\displaystyle \mathrm {tr} (\mathbf {A} _{1}\mathbf {A} _{2}\mathbf {A} _{3}\ldots \mathbf {A} _{n-2}\mathbf {A} _{n-1}\mathbf {A} _{n})=\mathrm {tr} (\mathbf {A} _{2}\mathbf {A} _{3}\mathbf {A} _{4}\ldots \mathbf {A} _{n-1}\mathbf {A} _{n}\mathbf {A} _{1})=\mathrm {tr} (\mathbf {A} _{3}\mathbf {A} _{4}\mathbf {A} _{5}\ldots \mathbf {A} _{n}\mathbf {A} _{1}\mathbf {A} _{2})=\ldots }




Determinant:
For square matrices only, the determinant of a product is the product of determinants:





det

(

∏

i
=
1


n




A


i


)

=

∏

i
=
1


n


det

(


A


i


)



{\displaystyle \det \left(\prod _{i=1}^{n}\mathbf {A} _{i}\right)=\prod _{i=1}^{n}\det \left(\mathbf {A} _{i}\right)}






Examples of chain multiplication[edit]
Similarity transformations involving similar matrices are matrix products of the three square matrices, in the form:






B

=


P


−
1



A


P



{\displaystyle \mathbf {B} =\mathbf {P} ^{-1}\mathbf {A} \mathbf {P} }



where P is the similarity matrix and A and B are said to be similar if this relation holds. This product appears frequently in linear algebra and applications, such as diagonalizing square matrices and the equivalence between different matrix representations of the same linear operator.
Operations derived from the matrix product[edit]
More operations on square matrices can be defined using the matrix product, such as powers and nth roots by repeated matrix products, the matrix exponential can be defined by a power series, the matrix logarithm is the inverse of matrix exponentiation, and so on.
Powers of matrices[edit]
Square matrices can be multiplied by themselves repeatedly in the same way as ordinary numbers, because they always have the same number of rows and columns. This repeated multiplication can be described as a power of the matrix, a special case of the ordinary matrix product. On the contrary, rectangular matrices do not have the same number of rows and columns so they can never be raised to a power. An n × n matrix A raised to a positive integer k is defined as







A


k


=




A


A

⋯

A



k


t
i
m
e
s






{\displaystyle \mathbf {A} ^{k}={\underset {k\mathrm {\,times} }{\mathbf {A} \mathbf {A} \cdots \mathbf {A} }}}



and the following identities hold, where λ is a scalar:


Zero power:







A


0


=

I



{\displaystyle \mathbf {A} ^{0}=\mathbf {I} }



where I is the identity matrix. This is parallel to the zeroth power of any number which equals unity.
Scalar multiplication:





(
λ

A


)

k


=

λ

k




A


k




{\displaystyle (\lambda \mathbf {A} )^{k}=\lambda ^{k}\mathbf {A} ^{k}}




Determinant:





det
(


A


k


)
=
det
(

A


)

k




{\displaystyle \det(\mathbf {A} ^{k})=\det(\mathbf {A} )^{k}}






The naive computation of matrix powers is to multiply k times the matrix A to the result, starting with the identity matrix just like the scalar case. This can be improved using exponentiation by squaring, a method commonly used for scalars. For diagonalizable matrices, an even better method is to use the eigenvalue decomposition of A. Another method based on the Cayley–Hamilton theorem finds an identity using the matrices' characteristic polynomial, producing a more effective equation for Ak in which a scalar is raised to the required power, rather than an entire matrix.
A special case is the power of a diagonal matrix. Since the product of diagonal matrices amounts to simply multiplying corresponding diagonal elements together, the power k of a diagonal matrix A will have entries raised to the power. Explicitly;







A


k


=



(




A

11




0


⋯


0




0



A

22




⋯


0




⋮


⋮


⋱


⋮




0


0


⋯



A

n
n





)



k


=


(




A

11


k




0


⋯


0




0



A

22


k




⋯


0




⋮


⋮


⋱


⋮




0


0


⋯



A

n
n


k





)




{\displaystyle \mathbf {A} ^{k}={\begin{pmatrix}A_{11}&0&\cdots &0\\0&A_{22}&\cdots &0\\\vdots &\vdots &\ddots &\vdots \\0&0&\cdots &A_{nn}\end{pmatrix}}^{k}={\begin{pmatrix}A_{11}^{k}&0&\cdots &0\\0&A_{22}^{k}&\cdots &0\\\vdots &\vdots &\ddots &\vdots \\0&0&\cdots &A_{nn}^{k}\end{pmatrix}}}



meaning it is easy to raise a diagonal matrix to a power. When raising an arbitrary matrix (not necessarily a diagonal matrix) to a power, it is often helpful to exploit this property by diagonalizing the matrix first.
Applications of the matrix product[edit]
Linear transformations[edit]
Main article: Linear transformations
Matrices offer a concise way of representing linear transformations between vector spaces, and matrix multiplication corresponds to the composition of linear transformations. The matrix product of two matrices can be defined when their entries belong to the same ring, and hence can be added and multiplied.
Let U, V, and W be vector spaces over the same field with given bases, S: V → W and T: U → V be linear transformations and ST: U → W be their composition.
Suppose that A, B, and C are the matrices representing the transformations S, T, and ST with respect to the given bases.
Then AB = C, that is, the matrix of the composition (or the product) of linear transformations is the product of their matrices with respect to the given bases.
Linear systems of equations[edit]
A system of linear equations with the same number of equations as variables can be solved by collecting the coefficients of the equations into a square matrix, then inverting the matrix equation.
A similar procedure can be used to solve a system of linear differential equations, see also phase plane.
Group theory and representation theory[edit]
Main articles: Group theory, Group representation, and Irrep
The inner and outer products[edit]
Given two column vectors a and b, the Euclidean inner product and outer product are the simplest special cases of the matrix product.[9]
Inner product[edit]
The inner product of two vectors in matrix form is equivalent to a column vector multiplied on its left by a row vector:










a

⋅

b




=


a



T




b







=


(




a

1





a

2




⋯



a

n





)




(




b

1







b

2






⋮





b

n





)








=

a

1



b

1


+

a

2



b

2


+
⋯
+

a

n



b

n








=

∑

i
=
1


n



a

i



b

i


,






{\displaystyle {\begin{aligned}\mathbf {a} \cdot \mathbf {b} &=\mathbf {a} ^{\mathrm {T} }\mathbf {b} \\&={\begin{pmatrix}a_{1}&a_{2}&\cdots &a_{n}\end{pmatrix}}{\begin{pmatrix}b_{1}\\b_{2}\\\vdots \\b_{n}\end{pmatrix}}\\&=a_{1}b_{1}+a_{2}b_{2}+\cdots +a_{n}b_{n}\\&=\sum _{i=1}^{n}a_{i}b_{i},\end{aligned}}}



where aT denotes the transpose of a.
The matrix product itself can be expressed in terms of inner product. Suppose that the first n × m matrix A is decomposed into its row vectors ai, and the second m × p matrix B into its column vectors bi:[1]






A

=


(




A

11





A

12




⋯



A

1
m







A

21





A

22




⋯



A

2
m






⋮


⋮


⋱


⋮





A

n
1





A

n
2




⋯



A

n
m





)


=


(





a


1








a


2






⋮






a


n





)


,


{\displaystyle \mathbf {A} ={\begin{pmatrix}A_{11}&A_{12}&\cdots &A_{1m}\\A_{21}&A_{22}&\cdots &A_{2m}\\\vdots &\vdots &\ddots &\vdots \\A_{n1}&A_{n2}&\cdots &A_{nm}\end{pmatrix}}={\begin{pmatrix}\mathbf {a} _{1}\\\mathbf {a} _{2}\\\vdots \\\mathbf {a} _{n}\end{pmatrix}},}









B

=


(




B

11





B

12




⋯



B

1
p







B

21





B

22




⋯



B

2
p






⋮


⋮


⋱


⋮





B

m
1





B

m
2




⋯



B

m
p





)


=


(





b


1






b


2




⋯




b


p





)




{\displaystyle \mathbf {B} ={\begin{pmatrix}B_{11}&B_{12}&\cdots &B_{1p}\\B_{21}&B_{22}&\cdots &B_{2p}\\\vdots &\vdots &\ddots &\vdots \\B_{m1}&B_{m2}&\cdots &B_{mp}\end{pmatrix}}={\begin{pmatrix}\mathbf {b} _{1}&\mathbf {b} _{2}&\cdots &\mathbf {b} _{p}\end{pmatrix}}}



where







a


i


=


(




A

i
1





A

i
2




⋯



A

i
m





)



,



b


i


=


(




B

1
i







B

2
i






⋮





B

m
i





)




{\displaystyle \mathbf {a} _{i}={\begin{pmatrix}A_{i1}&A_{i2}&\cdots &A_{im}\end{pmatrix}}\,,\quad \mathbf {b} _{i}={\begin{pmatrix}B_{1i}\\B_{2i}\\\vdots \\B_{mi}\end{pmatrix}}}



Then:






A
B

=


(





a


1








a


2






⋮






a


n





)




(





b


1






b


2




…




b


p





)


=


(



(


a


1


⋅


b


1


)


(


a


1


⋅


b


2


)


…


(


a


1


⋅


b


p


)




(


a


2


⋅


b


1


)


(


a


2


⋅


b


2


)


…


(


a


2


⋅


b


p


)




⋮


⋮


⋱


⋮




(


a


n


⋅


b


1


)


(


a


n


⋅


b


2


)


…


(


a


n


⋅


b


p


)



)




{\displaystyle \mathbf {AB} ={\begin{pmatrix}\mathbf {a} _{1}\\\mathbf {a} _{2}\\\vdots \\\mathbf {a} _{n}\end{pmatrix}}{\begin{pmatrix}\mathbf {b} _{1}&\mathbf {b} _{2}&\dots &\mathbf {b} _{p}\end{pmatrix}}={\begin{pmatrix}(\mathbf {a} _{1}\cdot \mathbf {b} _{1})&(\mathbf {a} _{1}\cdot \mathbf {b} _{2})&\dots &(\mathbf {a} _{1}\cdot \mathbf {b} _{p})\\(\mathbf {a} _{2}\cdot \mathbf {b} _{1})&(\mathbf {a} _{2}\cdot \mathbf {b} _{2})&\dots &(\mathbf {a} _{2}\cdot \mathbf {b} _{p})\\\vdots &\vdots &\ddots &\vdots \\(\mathbf {a} _{n}\cdot \mathbf {b} _{1})&(\mathbf {a} _{n}\cdot \mathbf {b} _{2})&\dots &(\mathbf {a} _{n}\cdot \mathbf {b} _{p})\end{pmatrix}}}



It is also possible to express a matrix product in terms of concatenations of products of matrices and row or column vectors:






A
B

=


(




A



b


1





A



b


2




…



A



b


p





)


=


(





a


1



B







a


2



B





⋮






a


n



B




)




{\displaystyle \mathbf {AB} ={\begin{pmatrix}\mathbf {A} \mathbf {b} _{1}&\mathbf {A} \mathbf {b} _{2}&\dots &\mathbf {A} \mathbf {b} _{p}\end{pmatrix}}={\begin{pmatrix}\mathbf {a} _{1}\mathbf {B} \\\mathbf {a} _{2}\mathbf {B} \\\vdots \\\mathbf {a} _{n}\mathbf {B} \end{pmatrix}}}



These decompositions are particularly useful for matrices that are envisioned as concatenations of particular types of row vectors or column vectors, e.g. orthogonal matrices (whose rows and columns are unit vectors orthogonal to each other) and Markov matrices (whose rows or columns sum to 1).[citation needed]
Outer product[edit]
The outer product (also known as the dyadic product or tensor product) of two vectors in matrix form is equivalent to a row vector multiplied on the left by a column vector:










a

⊗

b




=

a



b



T









=


(




a

1







a

2






⋮





a

n





)




(




b

1





b

2




⋯



b

n





)








=


(




a

1



b

1





a

1



b

2




⋯



a

1



b

n







a

2



b

1





a

2



b

2




⋯



a

2



b

n






⋮


⋮


⋱


⋮





a

n



b

1





a

n



b

2




⋯



a

n



b

n





)


.






{\displaystyle {\begin{aligned}\mathbf {a} \otimes \mathbf {b} &=\mathbf {a} \mathbf {b} ^{\mathrm {T} }\\&={\begin{pmatrix}a_{1}\\a_{2}\\\vdots \\a_{n}\end{pmatrix}}{\begin{pmatrix}b_{1}&b_{2}&\cdots &b_{n}\end{pmatrix}}\\&={\begin{pmatrix}a_{1}b_{1}&a_{1}b_{2}&\cdots &a_{1}b_{n}\\a_{2}b_{1}&a_{2}b_{2}&\cdots &a_{2}b_{n}\\\vdots &\vdots &\ddots &\vdots \\a_{n}b_{1}&a_{n}b_{2}&\cdots &a_{n}b_{n}\\\end{pmatrix}}.\end{aligned}}}



An alternative method is to express the matrix product in terms of the outer product. The decomposition is done the other way around, the first matrix A is decomposed into column vectors ai and the second matrix B into row vectors bi:










A
B




=


(







a
¯




1








a
¯




2




⋯






a
¯




m





)




(







b
¯




1










b
¯




2






⋮








b
¯




m





)








=




a
¯




1


⊗




b
¯




1


+




a
¯




2


⊗




b
¯




2


+
⋯
+




a
¯




m


⊗




b
¯




m








=

∑

i
=
1


m






a
¯




i


⊗




b
¯




i








{\displaystyle {\begin{aligned}\mathbf {AB} &={\begin{pmatrix}\mathbf {\bar {a}} _{1}&\mathbf {\bar {a}} _{2}&\cdots &\mathbf {\bar {a}} _{m}\end{pmatrix}}{\begin{pmatrix}\mathbf {\bar {b}} _{1}\\\mathbf {\bar {b}} _{2}\\\vdots \\\mathbf {\bar {b}} _{m}\end{pmatrix}}\\&=\mathbf {\bar {a}} _{1}\otimes \mathbf {\bar {b}} _{1}+\mathbf {\bar {a}} _{2}\otimes \mathbf {\bar {b}} _{2}+\cdots +\mathbf {\bar {a}} _{m}\otimes \mathbf {\bar {b}} _{m}\\&=\sum _{i=1}^{m}\mathbf {\bar {a}} _{i}\otimes \mathbf {\bar {b}} _{i}\end{aligned}}}



where this time









a
¯




i


=


(




A

1
i







A

2
i






⋮





A

n
i





)



,





b
¯




i


=


(




B

i
1





B

i
2




⋯



B

i
p





)



.


{\displaystyle \mathbf {\bar {a}} _{i}={\begin{pmatrix}A_{1i}\\A_{2i}\\\vdots \\A_{ni}\end{pmatrix}}\,,\quad \mathbf {\bar {b}} _{i}={\begin{pmatrix}B_{i1}&B_{i2}&\cdots &B_{ip}\end{pmatrix}}\,.}



This method emphasizes the effect of individual column/row pairs on the result, which is a useful point of view with e.g. covariance matrices, where each such pair corresponds to the effect of a single sample point.[citation needed]











(





1






2






3








4






5






6








7






8






9





)




(





a






d








b






e








c






f





)





=


(





1








4








7





)


⊗


(






a








d






)


+


(





2








5








8





)


⊗


(






b








e






)


+


(





3








6








9





)


⊗


(





c






f





)








=


(






1
a








1
d










4
a








4
d










7
a








7
d






)


+


(






2
b








2
e










5
b








5
e










8
b








8
e






)


+


(






3
c








3
f










6
c








6
f










9
c








9
f






)








=


(






1
a



+



2
b



+



3
c








1
d



+



2
e



+



3
f










4
a



+



5
b



+



6
c








4
d



+



5
e



+



6
f










7
a



+



8
b



+



9
c








7
d



+



8
e



+



9
f






)


.






{\displaystyle {\begin{aligned}{\begin{pmatrix}{\color {Brown}1}&{\color {Orange}2}&{\color {Violet}3}\\{\color {Brown}4}&{\color {Orange}5}&{\color {Violet}6}\\{\color {Brown}7}&{\color {Orange}8}&{\color {Violet}9}\\\end{pmatrix}}{\begin{pmatrix}{\color {Brown}a}&{\color {Brown}d}\\{\color {Orange}b}&{\color {Orange}e}\\{\color {Violet}c}&{\color {Violet}f}\\\end{pmatrix}}&={\begin{pmatrix}{\color {Brown}1}\\{\color {Brown}4}\\{\color {Brown}7}\\\end{pmatrix}}\otimes {\begin{pmatrix}{\color {Brown}{a}}&{\color {Brown}{d}}\\\end{pmatrix}}+{\begin{pmatrix}{\color {Orange}2}\\{\color {Orange}5}\\{\color {Orange}8}\\\end{pmatrix}}\otimes {\begin{pmatrix}{\color {Orange}{b}}&{\color {Orange}{e}}\\\end{pmatrix}}+{\begin{pmatrix}{\color {Violet}3}\\{\color {Violet}6}\\{\color {Violet}9}\\\end{pmatrix}}\otimes {\begin{pmatrix}{\color {Violet}c}&{\color {Violet}f}\\\end{pmatrix}}\\&={\begin{pmatrix}{\color {Brown}{1a}}&{\color {Brown}{1d}}\\{\color {Brown}{4a}}&{\color {Brown}{4d}}\\{\color {Brown}{7a}}&{\color {Brown}{7d}}\\\end{pmatrix}}+{\begin{pmatrix}{\color {Orange}{2b}}&{\color {Orange}{2e}}\\{\color {Orange}{5b}}&{\color {Orange}{5e}}\\{\color {Orange}{8b}}&{\color {Orange}{8e}}\\\end{pmatrix}}+{\begin{pmatrix}{\color {Violet}{3c}}&{\color {Violet}{3f}}\\{\color {Violet}{6c}}&{\color {Violet}{6f}}\\{\color {Violet}{9c}}&{\color {Violet}{9f}}\\\end{pmatrix}}\\&={\begin{pmatrix}{\color {Brown}{1a}}+{\color {Orange}{2b}}+{\color {Violet}{3c}}&{\color {Brown}{1d}}+{\color {Orange}{2e}}+{\color {Violet}{3f}}\\{\color {Brown}{4a}}+{\color {Orange}{5b}}+{\color {Violet}{6c}}&{\color {Brown}{4d}}+{\color {Orange}{5e}}+{\color {Violet}{6f}}\\{\color {Brown}{7a}}+{\color {Orange}{8b}}+{\color {Violet}{9c}}&{\color {Brown}{7d}}+{\color {Orange}{8e}}+{\color {Violet}{9f}}\\\end{pmatrix}}.\end{aligned}}}



Algorithms for efficient matrix multiplication[edit]
Main article: Matrix multiplication algorithm




The bound on ω over time.


The running time of square matrix multiplication, if carried out naïvely, is O(n3). The running time for multiplying rectangular matrices (one m × p-matrix with one p × n-matrix) is O(mnp), however, more efficient algorithms exist, such as Strassen's algorithm, devised by Volker Strassen in 1969 and often referred to as "fast matrix multiplication". It is based on a way of multiplying two 2 × 2-matrices which requires only 7 multiplications (instead of the usual 8), at the expense of several additional addition and subtraction operations. Applying this recursively gives an algorithm with a multiplicative cost of 



O
(

n


log

2


⁡
7


)
≈
O
(

n

2.807


)


{\displaystyle O(n^{\log _{2}7})\approx O(n^{2.807})}

. Strassen's algorithm is more complex, and the numerical stability is reduced compared to the naïve algorithm.[10] Nevertheless, it appears in several libraries, such as BLAS, where it is significantly more efficient for matrices with dimensions n > 100,[11] and is very useful for large matrices over exact domains such as finite fields, where numerical stability is not an issue.
The current O(nk) algorithm with the lowest known exponent k is a generalization of the Coppersmith–Winograd algorithm that has an asymptotic complexity of O(n2.3728639), by François Le Gall.[12] This algorithm, and the Coppersmith–Winograd algorithm on which it is based, are similar to Strassen's algorithm: a way is devised for multiplying two k × k-matrices with fewer than k3 multiplications, and this technique is applied recursively. However, the constant coefficient hidden by the Big O notation is so large that these algorithms are only worthwhile for matrices that are too large to handle on present-day computers.[13][14]
Since any algorithm for multiplying two n × n-matrices has to process all 2 × n2-entries, there is an asymptotic lower bound of Ω(n2) operations. Raz (2002) proves a lower bound of Ω(n2 log(n)) for bounded coefficient arithmetic circuits over the real or complex numbers.
Cohn et al. (2003, 2005) put methods such as the Strassen and Coppersmith–Winograd algorithms in an entirely different group-theoretic context, by utilising triples of subsets of finite groups which satisfy a disjointness property called the triple product property (TPP). They show that if families of wreath products of Abelian groups with symmetric groups realise families of subset triples with a simultaneous version of the TPP, then there are matrix multiplication algorithms with essentially quadratic complexity. Most researchers initially believed that this was indeed the case.[15] However, Blasiak, Church, Cohn, Grochow, Naslund, Sawin and Umans have recently shown using the Slice Rank method that such an approach using wreath products of abelian groups with small exponent, cannot yield a matrix multiplication exponent of 2. [16]
Freivalds' algorithm is a simple Monte Carlo algorithm that given matrices A, B, C verifies in Θ(n2) time if AB = C.




Block matrix multiplication. In the 2D algorithm, each processor is responsible for one submatrix of C. In the 3D algorithm, every pair of submatrices from A and B that is multiplied is assigned to one processor.


Parallel matrix multiplication[edit]
Because of the nature of matrix operations and the layout of matrices in memory, it is typically possible to gain substantial performance gains through use of parallelization and vectorization. Several algorithms are possible, among which divide and conquer algorithms based on the block matrix decomposition






C

=


(





C


11






C


12








C


21






C


22





)


=


(





A


11






A


12








A


21






A


22





)




(





B


11






B


12








B


21






B


22





)


=

A


B



{\displaystyle \mathbf {C} ={\begin{pmatrix}\mathbf {C} _{11}&\mathbf {C} _{12}\\\mathbf {C} _{21}&\mathbf {C} _{22}\\\end{pmatrix}}={\begin{pmatrix}\mathbf {A} _{11}&\mathbf {A} _{12}\\\mathbf {A} _{21}&\mathbf {A} _{22}\\\end{pmatrix}}{\begin{pmatrix}\mathbf {B} _{11}&\mathbf {B} _{12}\\\mathbf {B} _{21}&\mathbf {B} _{22}\\\end{pmatrix}}=\mathbf {A} \mathbf {B} }



that also underlies Strassen's algorithm. Here, A, B and C are presumed to be n by n (square) matrices, and C11 etc. are n/2 by n/2 submatrices. From this decomposition, one derives[17]







(





A


11






A


12








A


21






A


22





)




(





B


11






B


12








B


21






B


22





)


=


(





A


11




B


11


+


A


12




B


21






A


11




B


12


+


A


12




B


22








A


21




B


11


+


A


22




B


21






A


21




B


12


+


A


22




B


22





)




{\displaystyle {\begin{pmatrix}\mathbf {A} _{11}&\mathbf {A} _{12}\\\mathbf {A} _{21}&\mathbf {A} _{22}\\\end{pmatrix}}{\begin{pmatrix}\mathbf {B} _{11}&\mathbf {B} _{12}\\\mathbf {B} _{21}&\mathbf {B} _{22}\\\end{pmatrix}}={\begin{pmatrix}\mathbf {A} _{11}\mathbf {B} _{11}+\mathbf {A} _{12}\mathbf {B} _{21}&\mathbf {A} _{11}\mathbf {B} _{12}+\mathbf {A} _{12}\mathbf {B} _{22}\\\mathbf {A} _{21}\mathbf {B} _{11}+\mathbf {A} _{22}\mathbf {B} _{21}&\mathbf {A} _{21}\mathbf {B} _{12}+\mathbf {A} _{22}\mathbf {B} _{22}\\\end{pmatrix}}}



which consists of eight multiplications of pairs of submatrices, which can all be performed in parallel, followed by an addition step. Applying this recursively, and performing the additions in parallel as well, one obtains an algorithm that runs in Θ(log2 n) time on an ideal machine with an infinite number of processors, and has a maximum possible speedup of Θ(n3/(log2 n)) on any real computer (although the algorithm isn't practical, a more practical variant achieves Θ(n2) speedup).[17]
It should be noted that some lower time-complexity algorithms on paper may have indirect time complexity costs on real machines.
Communication-avoiding and distributed algorithms[edit]
On modern architectures with hierarchical memory, the cost of loading and storing input matrix elements tends to dominate the cost of arithmetic. On a single machine this is the amount of data transferred between RAM and cache, while on a distributed memory multi-node machine it is the amount transferred between nodes; in either case it is called the communication bandwidth. The naïve algorithm using three nested loops uses Ω(n3) communication bandwidth.
Cannon's algorithm, also known as the 2D algorithm, partitions each input matrix into a block matrix whose elements are submatrices of size √M/3 by √M/3, where M is the size of fast memory.[18] The naïve algorithm is then used over the block matrices, computing products of submatrices entirely in fast memory. This reduces communication bandwidth to O(n3/√M), which is asymptotically optimal (for algorithms performing Ω(n3) computation).[19][20]
In a distributed setting with p processors arranged in a √p by √p 2D mesh, one submatrix of the result can be assigned to each processor, and the product can be computed with each processor transmitting O(n2/√p) words, which is asymptotically optimal assuming that each node stores the minimum O(n2/p) elements.[20] This can be improved by the 3D algorithm, which arranges the processors in a 3D cube mesh, assigning every product of two input submatrices to a single processor. The result submatrices are then generated by performing a reduction over each row.[21] This algorithm transmits O(n2/p2/3) words per processor, which is asymptotically optimal.[20] However, this requires replicating each input matrix element p1/3 times, and so requires a factor of p1/3 more memory than is needed to store the inputs. This algorithm can be combined with Strassen to further reduce runtime.[21] "2.5D" algorithms provide a continuous tradeoff between memory usage and communication bandwidth.[22] On modern distributed computing environments such as MapReduce, specialized multiplication algorithms have been developed.[23]
Other forms of multiplication[edit]
The term "matrix multiplication" is most commonly reserved for the definition given in this article. It could be more loosely applied to other definitions.

Hadamard product (matrices)
Frobenius inner product
Kronecker product
Cracovian product

See also[edit]



Wikimedia Commons has media related to matrix multiplication.




Basic Linear Algebra Subprograms
Composition of relations
Logical matrix
Matrix analysis
Matrix inversion
Matrix multiplication algorithm


Notes[edit]


^ a b Lerner, R. G.; Trigg, G. L. (1991). Encyclopaedia of Physics (2nd ed.). VHC publishers. ISBN 3-527-26954-1. 
^ Parker, C. B. (1994). McGraw Hill Encyclopaedia of Physics (2nd ed.). ISBN 0-07-051400-3. 
^ Lipschutz, S.; Lipson, M. (2009). Linear Algebra. Schaum's Outlines (4th ed.). McGraw Hill (USA). pp. 30–31. ISBN 978-0-07-154352-1. 
^ Riley, K. F.; Hobson, M. P.; Bence, S. J. (2010). Mathematical methods for physics and engineering. Cambridge University Press. ISBN 978-0-521-86153-3. 
^ Adams, R. A. (1995). Calculus, A Complete Course (3rd ed.). Addison Wesley. p. 627. ISBN 0 201 82823 5. 
^ Horn, Johnson (2013). Matrix Analysis (2nd ed.). Cambridge University Press. p. 6. ISBN 978 0 521 54823 6. 
^ Lipcshutz, S.; Lipson, M. (2009). "2". Linear Algebra. Schaum's Outlines (4th ed.). McGraw Hill (USA). ISBN 978-0-07-154352-1. 
^ Horn, Johnson (2013). "0". Matrix Analysis (2nd ed.). Cambridge University Press. ISBN 978 0 521 54823 6. 
^ Mathematical methods for physics and engineering, K.F. Riley, M.P. Hobson, S.J. Bence, Cambridge University Press, 2010, ISBN 978-0-521-86153-3
^ Miller, Webb (1975), "Computational complexity and numerical stability", SIAM News, 4: 97–107, CiteSeerX 10.1.1.148.9947 , doi:10.1137/0204009 
^ Press 2007, p. 108.
^ Le Gall, François (2014), "Powers of tensors and fast matrix multiplication", Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation (ISSAC 2014), arXiv:1401.7714  . The original algorithm was presented by Don Coppersmith and Shmuel Winograd in 1990, has an asymptotic complexity of O(n2.376). It was improved in 2013 to O(n2.3729) by Virginia Vassilevska Williams, giving a time only slightly worse than Le Gall's improvement: Williams, Virginia Vassilevska. "Multiplying matrices faster than Coppersmith-Winograd" (PDF). 
^ Iliopoulos, Costas S. (1989), "Worst-case complexity bounds on algorithms for computing the canonical structure of finite abelian groups and the Hermite and Smith normal forms of an integer matrix" (PDF), SIAM Journal on Computing, 18 (4): 658–669, MR 1004789, doi:10.1137/0218045, The Coppersmith–Winograd algorithm is not practical, due to the very large hidden constant in the upper bound on the number of multiplications required. 
^ Robinson, Sara (2005), "Toward an Optimal Algorithm for Matrix Multiplication" (PDF), SIAM News, 38 (9) 
^ Robinson, 2005.
^ [Jonah Blasiak, Thomas Church, Henry Cohn, Joshua A. Grochow, Eric Naslund, William F. Sawin, Chris Umans, On cap sets and the group-theoretic approach to matrix multiplication
^ a b Randall, Keith H. (1998). Cilk: Efficient Multithreaded Computing (PDF) (Ph.D.). Massachusetts Institute of Technology. pp. 54–57. 
^ Lynn Elliot Cannon, A cellular computer to implement the Kalman Filter Algorithm, Technical report, Ph.D. Thesis, Montana State University, 14 July 1969.
^ Hong, J.W.; Kung, H. T. (1981). "I/O complexity: The red-blue pebble game". STOC ’81: Proceedings of the thirteenth annual ACM symposium on Theory of computing: 326–333. 
^ a b c Irony, Dror; Toledo, Sivan; Tiskin, Alexander (September 2004). "Communication lower bounds for distributed-memory matrix multiplication". J. Parallel Distrib. Comput. 64 (9): 1017–1026. doi:10.1016/j.jpdc.2004.03.021. 
^ a b Agarwal, R.C.; Balle, S. M.; Gustavson, F. G.; Joshi, M.; Palkar, P. (September 1995). "A three-dimensional approach to parallel matrix multiplication". IBM J. Res. Dev. 39 (5): 575–582. doi:10.1147/rd.395.0575. 
^ Solomonik, Edgar; Demmel, James (2011). "Communication-optimal parallel 2.5D matrix multiplication and LU factorization algorithms". Proceedings of the 17th international conference on Parallel processing. Part II: 90–109. doi:10.1007/978-3-642-23397-5_10. 
^ Pietracaprina, A.; Pucci, G.; Riondato, M.; Silvestri, F.; Upfal, E. (2012). "Space-Round Tradeoffs for MapReduce Computations". Proc. of 26th ACM International Conference on Supercomputing. Venice (Italy): ACM. pp. 235–244. doi:10.1145/2304576.2304607. 


References[edit]


Henry Cohn, Robert Kleinberg, Balázs Szegedy, and Chris Umans. Group-theoretic Algorithms for Matrix Multiplication. arXiv:math.GR/0511460. Proceedings of the 46th Annual Symposium on Foundations of Computer Science, 23–25 October 2005, Pittsburgh, PA, IEEE Computer Society, pp. 379–388.
Henry Cohn, Chris Umans. A Group-theoretic Approach to Fast Matrix Multiplication. arXiv:math.GR/0307321. Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, 11–14 October 2003, Cambridge, MA, IEEE Computer Society, pp. 438–449.
Coppersmith, D.; Winograd, S. (1990). "Matrix multiplication via arithmetic progressions". J. Symbolic Comput. 9: 251–280. doi:10.1016/s0747-7171(08)80013-2. 
Horn, Roger A.; Johnson, Charles R. (1991), Topics in Matrix Analysis, Cambridge University Press, ISBN 978-0-521-46713-1 
Knuth, D.E., The Art of Computer Programming Volume 2: Seminumerical Algorithms. Addison-Wesley Professional; 3 edition (November 14, 1997). ISBN 978-0-201-89684-8. pp. 501.
Press, William H.; Flannery, Brian P.; Teukolsky, Saul A.; Vetterling, William T. (2007), Numerical Recipes: The Art of Scientific Computing (3rd ed.), Cambridge University Press, ISBN 978-0-521-88068-8 .
Ran Raz. On the complexity of matrix product. In Proceedings of the thirty-fourth annual ACM symposium on Theory of computing. ACM Press, 2002. doi:10.1145/509907.509932.
Robinson, Sara, Toward an Optimal Algorithm for Matrix Multiplication, SIAM News 38(9), November 2005. PDF
Strassen, Volker, Gaussian Elimination is not Optimal, Numer. Math. 13, p. 354-356, 1969.
Styan, George P. H. (1973), "Hadamard Products and Multivariate Statistical Analysis", Linear Algebra and its Applications, 6: 217–240, doi:10.1016/0024-3795(73)90023-2 
Vassilevska Williams, Virginia, Multiplying matrices faster than Coppersmith-Winograd, Manuscript, May 2012. PDF


External links[edit]



The Wikibook The Book of Mathematical Proofs has a page on the topic of: Proofs of properties of matrices





The Wikibook Linear Algebra has a page on the topic of: Matrix multiplication





The Wikibook Applicable Mathematics has a page on the topic of: Multiplying Matrices



Matrix Multiplication
How to Multiply Matrices
Matrix Multiplication Calculator Online
The Simultaneous Triple Product Property and Group-theoretic Results for the Exponent of Matrix Multiplication
WIMS Online Matrix Multiplier
Wijesuriya, Viraj B., Daniweb: Sample Code for Matrix Multiplication using MPI Parallel Programming Approach, retrieved 2010-12-29 
Linear algebra: matrix operations Multiply or add matrices of a type and with coefficients you choose and see how the result was computed.
Matrix Multiplication in Java – Dr. P. Viry
"Matrix multiplication as composition". Essence of linear algebra. August 8, 2016 – via YouTube. 







v
t
e


Algebra



General



Elementary algebra
Abstract algebra
Commutative algebra
Order theory
Category theory
K-theory





Algebraic structures



Group (theory)
Ring (theory)
Field (theory)
Universal algebra





Linear algebra



Matrix (theory)
Vector space (Vector)
Inner product space
Geometric algebra (Multivector)
Hilbert space





Topic lists



Abstract algebra
Algebraic structures
Group theory
Linear algebra





Glossaries



Field theory
Linear algebra
Ring theory






Portal








 
						Retrieved from "https://en.wikipedia.org/w/index.php?title=Matrix_multiplication&oldid=791871690"					
Categories: Matrix theoryBilinear operatorsBinary operationsMultiplicationNumerical linear algebraHidden categories: All articles with unsourced statementsArticles with unsourced statements from March 2014 



Navigation menu


Personal tools

Not logged inTalkContributionsCreate accountLog in 



Namespaces

Article
Talk




Variants









Views

Read
Edit
View history



More







Search



 







Navigation


Main pageContentsFeatured contentCurrent eventsRandom articleDonate to WikipediaWikipedia store 



Interaction


HelpAbout WikipediaCommunity portalRecent changesContact page 



Tools


What links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationWikidata itemCite this page 



Print/export


Create a bookDownload as PDFPrintable version 



In other projects


Wikimedia Commons 



Languages


العربيةবাংলাБългарскиCatalàČeštinaDeutschEspañolEsperantoفارسیFrançais한국어ItalianoעבריתLatviešuNederlands日本語PolskiPortuguêsРусскийதமிழ்TürkçeУкраїнськаTiếng Việt中文 
Edit links 





 This page was last edited on 23 July 2017, at 00:35.
Text is available under the Creative Commons Attribution-ShareAlike License;
additional terms may apply.  By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.


Privacy policy
About Wikipedia
Disclaimers
Contact Wikipedia
Developers
Cookie statement
Mobile view



 

 











Eigen: The Array class and coefficient-wise operations


























Eigen
    3.3.4


 





























 All Classes Namespaces Functions Variables Typedefs Enumerations Enumerator Friends Groups Pages







The Array class and coefficient-wise operationsDense matrix and array manipulation 


This page aims to provide an overview and explanations on how to use Eigen's Array class.

What is the Array class?
The Array class provides general-purpose arrays, as opposed to the Matrix class which is intended for linear algebra. Furthermore, the Array class provides an easy way to perform coefficient-wise operations, which might not have a linear algebraic meaning, such as adding a constant to every coefficient in the array or multiplying two arrays coefficient-wise.

Array types
Array is a class template taking the same template parameters as Matrix. As with Matrix, the first three template parameters are mandatory: 
Array<typename Scalar, int RowsAtCompileTime, int ColsAtCompileTime>
 The last three template parameters are optional. Since this is exactly the same as for Matrix, we won't explain it again here and just refer to The Matrix class.
Eigen also provides typedefs for some common cases, in a way that is similar to the Matrix typedefs but with some slight differences, as the word "array" is used for both 1-dimensional and 2-dimensional arrays. We adopt the convention that typedefs of the form ArrayNt stand for 1-dimensional arrays, where N and t are the size and the scalar type, as in the Matrix typedefs explained on this page. For 2-dimensional arrays, we use typedefs of the form ArrayNNt. Some examples are shown in the following table:


Type  Typedef   

Array<float,Dynamic,1> 
 ArrayXf 
 

Array<float,3,1> 
 Array3f 
 

Array<double,Dynamic,Dynamic> 
 ArrayXXd 
 

Array<double,3,3> 
 Array33d 
 


Accessing values inside an Array
The parenthesis operator is overloaded to provide write and read access to the coefficients of an array, just as with matrices. Furthermore, the << operator can be used to initialize arrays (via the comma initializer) or to print them.


Example:Output: 

#include <Eigen/Dense>
#include <iostream>

using namespace Eigen;
using namespace std;

int main()
{
  ArrayXXf  m(2,2);
 
 // assign some values coefficient by coefficient
  m(0,0) = 1.0; m(0,1) = 2.0;
  m(1,0) = 3.0; m(1,1) = m(0,1) + m(1,0);
 
 // print values to standard output
  cout << m << endl << endl;
 
 // using the comma-initializer is also allowed
  m << 1.0,2.0,
       3.0,4.0;
 
 // print values to standard output
  cout << m << endl;
}
 1 2
3 5

1 2
3 4
 

For more information about the comma initializer, see Advanced initialization.

Addition and subtraction
Adding and subtracting two arrays is the same as for matrices. The operation is valid if both arrays have the same size, and the addition or subtraction is done coefficient-wise.
Arrays also support expressions of the form array + scalar which add a scalar to each coefficient in the array. This provides a functionality that is not directly available for Matrix objects.


Example:Output: 

#include <Eigen/Dense>
#include <iostream>

using namespace Eigen;
using namespace std;

int main()
{
  ArrayXXf a(3,3);
  ArrayXXf b(3,3);
  a << 1,2,3,
       4,5,6,
       7,8,9;
  b << 1,2,3,
       1,2,3,
       1,2,3;
 
 // Adding two arrays
  cout << "a + b = " << endl << a + b << endl << endl;

 // Subtracting a scalar from an array
  cout << "a - 2 = " << endl << a - 2 << endl;
}
 a + b = 
 2  4  6
 5  7  9
 8 10 12

a - 2 = 
-1  0  1
 2  3  4
 5  6  7
 


Array multiplication
First of all, of course you can multiply an array by a scalar, this works in the same way as matrices. Where arrays are fundamentally different from matrices, is when you multiply two together. Matrices interpret multiplication as matrix product and arrays interpret multiplication as coefficient-wise product. Thus, two arrays can be multiplied if and only if they have the same dimensions.


Example:Output: 

#include <Eigen/Dense>
#include <iostream>

using namespace Eigen;
using namespace std;

int main()
{
  ArrayXXf a(2,2);
  ArrayXXf b(2,2);
  a << 1,2,
       3,4;
  b << 5,6,
       7,8;
  cout << "a * b = " << endl << a * b << endl;
}
 a * b = 
 5 12
21 32
 


Other coefficient-wise operations
The Array class defines other coefficient-wise operations besides the addition, subtraction and multiplication operators described above. For example, the .abs()  method takes the absolute value of each coefficient, while .sqrt()  computes the square root of the coefficients. If you have two arrays of the same size, you can call .min(.)  to construct the array whose coefficients are the minimum of the corresponding coefficients of the two given arrays. These operations are illustrated in the following example.


Example:Output: 

#include <Eigen/Dense>
#include <iostream>

using namespace Eigen;
using namespace std;

int main()
{
  ArrayXf a = ArrayXf::Random(5);
  a *= 2;
  cout << "a =" << endl 
       << a << endl;
  cout << "a.abs() =" << endl 
       << a.abs() << endl;
  cout << "a.abs().sqrt() =" << endl 
       << a.abs().sqrt() << endl;
  cout << "a.min(a.abs().sqrt()) =" << endl 
       << a.min(a.abs().sqrt()) << endl;
}
 a =
  1.36
-0.422
  1.13
  1.19
  1.65
a.abs() =
 1.36
0.422
 1.13
 1.19
 1.65
a.abs().sqrt() =
1.17
0.65
1.06
1.09
1.28
a.min(a.abs().sqrt()) =
  1.17
-0.422
  1.06
  1.09
  1.28
 

More coefficient-wise operations can be found in the Quick reference guide.

Converting between array and matrix expressions
When should you use objects of the Matrix class and when should you use objects of the Array class? You cannot apply Matrix operations on arrays, or Array operations on matrices. Thus, if you need to do linear algebraic operations such as matrix multiplication, then you should use matrices; if you need to do coefficient-wise operations, then you should use arrays. However, sometimes it is not that simple, but you need to use both Matrix and Array operations. In that case, you need to convert a matrix to an array or reversely. This gives access to all operations regardless of the choice of declaring objects as arrays or as matrices.
Matrix expressions  have an .array()  method that 'converts' them into array expressions, so that coefficient-wise operations can be applied easily. Conversely, array expressions  have a .matrix()  method. As with all Eigen expression abstractions, this doesn't have any runtime cost (provided that you let your compiler optimize). Both .array()  and .matrix()  can be used as rvalues and as lvalues.
Mixing matrices and arrays in an expression is forbidden with Eigen. For instance, you cannot add a matrix and array directly; the operands of a + operator should either both be matrices or both be arrays. However, it is easy to convert from one to the other with .array()  and .matrix(). The exception to this rule is the assignment operator: it is allowed to assign a matrix expression to an array variable, or to assign an array expression to a matrix variable.
The following example shows how to use array operations on a Matrix object by employing the .array()  method. For example, the statement result = m.array() * n.array() takes two matrices m and n, converts them both to an array, uses to multiply them coefficient-wise and assigns the result to the matrix variable result (this is legal because Eigen allows assigning array expressions to matrix variables).
As a matter of fact, this usage case is so common that Eigen provides a const .cwiseProduct(.)  method for matrices to compute the coefficient-wise product. This is also shown in the example program.


Example:Output: 

#include <Eigen/Dense>
#include <iostream>

using namespace Eigen;
using namespace std;

int main()
{
 MatrixXf m(2,2);
 MatrixXf n(2,2);
 MatrixXf result(2,2);

  m << 1,2,
       3,4;
  n << 5,6,
       7,8;

  result = m * n;
  cout << "-- Matrix m*n: --" << endl << result << endl << endl;
  result = m.array() * n.array();
  cout << "-- Array m*n: --" << endl << result << endl << endl;
  result = m.cwiseProduct(n);
  cout << "-- With cwiseProduct: --" << endl << result << endl << endl;
  result = m.array() + 4;
  cout << "-- Array m + 4: --" << endl << result << endl << endl;
}
 -- Matrix m*n: --
19 22
43 50

-- Array m*n: --
 5 12
21 32

-- With cwiseProduct: --
 5 12
21 32

-- Array m + 4: --
5 6
7 8

 

Similarly, if array1 and array2 are arrays, then the expression array1.matrix() * array2.matrix() computes their matrix product.
Here is a more advanced example. The expression (m.array() + 4).matrix() * m adds 4 to every coefficient in the matrix m and then computes the matrix product of the result with m. Similarly, the expression (m.array() * n.array()).matrix() * m computes the coefficient-wise product of the matrices m and n and then the matrix product of the result with m.


Example:Output: 

#include <Eigen/Dense>
#include <iostream>

using namespace Eigen;
using namespace std;

int main()
{
 MatrixXf m(2,2);
 MatrixXf n(2,2);
 MatrixXf result(2,2);

  m << 1,2,
       3,4;
  n << 5,6,
       7,8;
 
  result = (m.array() + 4).matrix() * m;
  cout << "-- Combination 1: --" << endl << result << endl << endl;
  result = (m.array() * n.array()).matrix() * m;
  cout << "-- Combination 2: --" << endl << result << endl << endl;
}
 -- Combination 1: --
23 34
31 46

-- Combination 2: --
 41  58
117 170

 






Generated on Wed Aug 2 2017 06:37:53 for Eigen by
    
 1.8.5 

















Ecolab Home 













































































 


 


 







 



English
Investors
Safety Data Sheets
Login

 
Search






























 


        A Water Awakening

    

        With innovative solutions and insights, we help customers around the world do more with less to meet demand and ensure water will be available for future generations.
    

Watch Video

 



×



 








 


        Doing More with Less

    

        We're partnering with customers to conserve water where it matters most
    

Watch Video

 



×



 








 


        Protecting what's vital

    

        Treating water - and all of our limited resources with unlimited resourcefulness
    

Watch VideoLearn More

 



×



 








 


        Keeping Food Safe Sustainably

    

        How we're helping a leader in food safety and sustainability achieve their goals
    

Watch VideoLearn More

 



×



 













Previous slide



Next slide








        Finding solutions to the

            
world's biggest challenges    

Clean water

safe food

abundant energy

healthy environments










        Latest NEWS

    


 








View all News
 










        Contact Us

    



Expand






        GET IN TOUCH


With unparalleled expertise and cutting-edge technology, we partner with customers to deliver world-class results and optimized operations. Contact us to learn how we can help you.








        GIVE US A CALL

    

Ecolab Inc.
1 Ecolab Place
St. Paul, MN 55102

Ecolab Customer Service

Phone: 800-352-5326
Fax: +1-651-225-3098
Email: institutionalorders@ecolab.com 



Nalco Water Customer Service 
Phone: 1-800-288-0879

Fax: 1-800-288-0878

Email: customerservice.us@nalco.com

Nalco Champion Customer Service 
Phone: 1-877-288-3512

Fax: 1-877-288-3513

Email: nes.keyaccounts.na@nalco.com 





 

                Ecolab, 1 Ecolab Place, St. Paul, MN 55102
            








Contact Us If you have an urgent request, please call Customer Service at 1 800 352-5326.




NameEmailPhoneCompanyCurrent Customer 



                Yes
            





                No
            

Industry
Buildings & Facilities
Chemical Processing Plants
Commercial Laundries
Energy Exploration & Production
Food & Beverage Manufacturing
Foodservice
Healthcare
Hospitality
Manufacturing
Mining & Mineral Processing
Oil & Gas Midstream
Power Generation
Primary Metals
Pulp & Paper
Refining, Additives & Petrochemical
Retail
Location Address
Location CityStateLocation ZIP CodeCountryAfghanistan
Albania
Algeria
American Samoa
Andorra
Angola
Anguilla
Antigua and Barbuda
Areas not specified
Argentina
Armenia
Aruba
Australia
Austria
Azerbaijan
Bahamas
Bahrain
Bangladesh
Barbados
Belarus
Belgium
Belize
Benin
Bermuda
Bhutan
Bolivia
Bosnia and Herzegovina
Botswana
Brazil
British Virgin Islands
Brunei Darussalam
Bulgaria
Burkina Faso
Burundi
Cambodia
Cameroon
Canada
Cape Verde
Cayman Islands
Central African Republic
Chad
Channel Islands
Chile
China
Columbia
Comoros
Congo
Cook Islands
Costa Rica
Croatia
Cuba
Cyprus
Czech Republic
Democratic Peoples Republic of Korea
Democratic Republic of the Congo
Denmark
Djibouti
Dominica
Dominican Republic
East Timor
Ecuador
Egypt
El Salvador
Equatorial Guinea
Eritrea
Estonia
Ethiopia
Faeroe Islands
Falkland Islands
Fiji
Finland
France
French Guiana
French Polynesia
Gabon
Gambia
Georgia
Germany
Ghana
Gibraltar
Greece
Greenland
Grenada
Guadeloupe
Guam
Guatemala
Guinea
Guinea-Bissau
Guyana
Haiti
Holy See
Honduras
Hong Kong
Hungary
Iceland
India
Indonesia
Iran
Iraq
Ireland
Isle of Man
Israel
Italy
Ivory Coast
Jamaica
Japan
Jordan
Kazakhstan
Kenya
Kiribati
Kuwait
Kyrgyzstan
Laos
Latvia
Lebanon
Lesotho
Liberia
Libya
Liechtenstein
Lithuania
Luxembourg
Macau
Macedonia
Madagascar
Malawi
Malaysia
Maldives
Mali
Malta
Marshall Islands
Martinique
Mauritania
Mauritius
Mexico
Micronesia
Monaco
Mongolia
Montserrat
Morocco
Mozambique
Myanmar
Namibia
Nauru
Nepal
Netherlands
Netherlands Antilles
New Caledonia
New Zealand
Nicaragua
Niger
Nigeria
Niue
Norfolk Island
Northern Mariana Islands
Norway
Occupied Palestinian Territory
Oman
Pakistan
Palau
Panama
Papua New Guinea
Paraguay
Peru
Philippines
Pitcairn
Poland
Portugal
Puerto Rico
Qatar
Republic of Korea
Republic of Moldova
R'union
Romania
Russian Federation
Rwanda
Saint Helena
Saint Kitts and Nevis
Saint Lucia
Saint Pierre and Miquelon
Saint Vincent and the Grenadines
Samoa
San Marino
Sao Tome and Principe
Saudi Arabia
Senegal
Seychelles
Sierra Leone
Singapore
Slovakia
Slovenia
Solomon Islands
Somalia
South Africa
Spain
Sri Lanka
Sudan
Suriname
Svalbard and Jan Mayen Islands
Swaziland
Sweden
Switzerland
Syria
Taiwan
Tajikistan
Tanzania
Thailand
Togo
Tokelau
Tonga
Trinidad and Tobago
Tunisia
Turkey
Turkmenistan
Turks and Caicos Islands
Tuvalu
Uganda
Ukraine
United Arab Emirates
United Kingdom
United States
United States Virgin Islands
Uruguay
Uzbekistan
Vanuatu
Venezuela
Viet Nam
Wallis and Futuna Islands
Western Sahara
Yemen
Yugoslavia
Zambia
Zimbabwe
Select your CountryNotes
Request Type
Price, Quote, Proposal or Sample Request
Equipment Service/Repair Request
Order/Delivery/Shipping Questions
Technical Support
Distributor/Partnership/Supplier Request
Research & Engineering Request
Invoice Question
Payment Request
MyNalco.com Access Request
One Ecolab Access Request
Donation/Sponsorship Request
Other Request
Division
EcoSure
Energy Services
Food & Beverage
Food Safety Specialists
GCS (EEC)
GCS (EUC)
Healthcare
Institutional
Kay
Kay Chemical / FRS
Kay Chemical / Global
Kay Chemical / GRS
Kay Chemical / QSR
Pest Elimination
PureForce
Textile Care
Vehicle Care
WPS
reCaptcha

Hidden


RecordTypeIdoriginownerexternalReferring URL













 










            Clean Water

        

From conserving to reusing and recycling, we're safeguarding the world's most precious resource.


Learn More











            Safe Food

        

With a world hungry for safe food solutions, we keep serving up new ideas.


Learn More











            Abundant Energy

        

Progress never stops - and we're helping take energy further by doing more with less.


Learn More











            Healthy Environments

        

We protect the places where people eat, sleep, work, play and heal.


Learn More



 
























About Surgical Tables Inc. | Surgical Tables Inc















































 






 


















Products

Bariatric surgery x-ray tables
Custom surgical tables
EconoMAX surgical tables
MAX surgical tables
Streamline imaging tables
URO-MAX urological tables
V-MAX surgical tables
 

Medical specialities

Pain management tables
Interventional radiology tables
Interventional radiology tables
Vascular C-arm tables
Urology, lithotripsy & nephrology tables
ERCP & GI tables
Bariatric surgery tables

Why STI?

4-way float tables
C-arm tables
Imaging tables
OR tables
Pain management tables
Radiology tables
Urology tables
Used surgical tables
Vascular tables
X-ray c-arm tables

 















Pages 
About cookies
About us

Careers
Privacy policy
Terms of use


Contact
Medical specialities

Bariatric surgery tables
ERCP & GI tables
Interventional radiology tables
Interventional radiology tables
Pain management tables
Urology, lithotripsy & nephrology tables
Vascular C-arm tables


Privacy policy
Products

Bariatric surgery x-ray tables
Custom surgical tables
EconoMAX surgical tables
MAX surgical tables
Streamline imaging tables
URO-MAX urological tables
V-MAX surgical tables


Surgical tables
Terms of use
Testimonials

Testimonials from doctors

Jonathan Vapnek, Urologist
Steven Beverly, M.D., M.S., FACOG


Testimonials from end users


Thank you for contacting us
Thank you for signing up to our newsletter
Welcome to Surgical tables
Why STI?

4-way float tables
C-arm tables
Imaging tables
OR tables
Pain management tables
Radiology tables
Urology tables
Used surgical tables
Vascular tables
X-ray c-arm tables



  News & events 

Come see our urology C-Arm table at AUA 2017 in Boston May 13-15!
May 9, 2017


Welcome to our new website!
January 18, 2017


American Urology Association’s 2015 Annual Meeting | May 15 – 19
December 21, 2016


Radiological Society of North America Annual Meeting | Nov 30 – Dec 5
December 21, 2016


 



Subscribe to our newsletter: 
Sign up 


Home | About us About us
Surgical Tables Inc is a top manufacturer of quality surgical tables that has been building tables since 2004. 
Surgical Tables Inc was acquired by ADDvise Group AB in 2014. ADDvise Group AB (publ) is a leading supplier of equipment to healthcare and research facilities. The group consists of approximately 10 subsidiaries organized into two business areas, Lab and Healthcare. Sales are global. The Group has a clear acquisition strategy with the aim of raising shareholder value and expand the business – both geographically and product wise. The Group has sales of about 250 MSEK. ADDvise shares are listed on Nasdaq First North Premier. Additional information is available at www.addvisegroup.com. 
Surgical Tables primary focus is on major health care markets with significant growth potential, driven by the demand for better, more cost-effective treatments that offer patients an improved quality of care. Each of our product lines offers the following characteristics:
Versatility
STI provides a flexible solution for the medical and budgetary concerns of all surgical environments.
Technologically Advanced
Designed to support the latest advancements in surgical procedures and imaging techniques, setting the standard for operating efficiency.
Cost-Effectiveness
Attractive ratio of price to performance frees up space in your investment planning and the rugged engineering features keep your follow-up costs low.
Safety
Surgical Tables offers fully automated adjustment of all table functions for safe, trauma-free positioning of the patient without compromising the health and safety of the medical staff.
Compliance
Surgical Tables Incorporated (STI) manufactures medical devices that are compliant with the Center for Devices and Radiological Health (CDRH) Code of Federal Regulation 21 Subchapter J Part 1020 Section 30 (CFR21 Subchapter J part 1020.30), the performance standard for ionizing radiation emitting products. Additionally, STI’s products are manufactured according to the Food & Drug Administration’s (FDA) Current Good Manufacturing Practices (CGMP).
Quality
Versatility, technology, cost, safety and compliance. For all these reasons and more Surgical Tables Inc. is fast becoming the industry leader in surgical table quality.
 






Subscribe to our newsletter: 
Sign up 








Newsletter
Please enter your name, email address, company name and optional phone number to sign up for our quarterly newsletter.

Email address*

Name*Company Name*PhoneUser TypeDealerEnd UserEmail formatHTMLTEXTEmailThis field is for validation purposes and should be left unchanged.

  










This iframe contains the logic required to handle AJAX powered Gravity Forms.
 


Newsletter
Please enter your name, email address, company name and optional phone number to sign up for our quarterly newsletter.

Email address*

Name*Company Name*PhoneUser TypeDealerEnd UserEmail formatHTMLTEXTNameThis field is for validation purposes and should be left unchanged.

  










This iframe contains the logic required to handle AJAX powered Gravity Forms.










We use cookies to ensure that we give you the best experience on our website. If you continue to use this site we will assume that you are happy with it.OkRead more




 



Bitwise Group: Enabling Innovation
























































































 








 





point-of-sale payments
		

read more








automotive to locomotive
		

read more








advanced medical instruments
		

read more








personal healthcare
		

read more








driving business success
		

read more



 







Bitwise - enabling business and technological innovation Your strategic partner for high quality software development
Staying in touchStay in touch with us and keep informed of our latest updates via the following social media. Alternatively use the popup window to download our brochure for detailed information on our services.

Collaborating for your successThe increasing rate of innovation in sectors ranging from healthcare to telecommunications is dramatically shortening the life cycle of many applications and products that rely on software for their operation.
These days, collaboration is increasingly important and many multinational OEMs are establishing global development ecosystems to stay ahead of their competition. To collaborate successfully, such companies need more than just offshore software development or teams of local contractors working on piecemeal projects. They need a software partner that shares their vision and can be relied on to provide system architecture, software, testing, tools and methodologies that support their long-term development road map.
We share the vision and product strategies of our clients. Our partnership approach to system consulting and software development ensures our full commitment to increasing the effectiveness of our clients’ innovations.
Bitwise is a leading consulting and development service partner. Our engagement model helps clients shorten time-to-market, improve end-user experience and manage product life-cycles. Leveraging over 25 years software expertise and sector experience, our development services enable our clients to innovate faster and optimize the realization of new developments.



Offering you a fast-start development serviceWith Bitwise you have the assurance that you’re working with a specialist developer capable of assigning software  engineering experts with exactly the right sector knowledge. This enables fast-start development and shorter time to market.
read more...




Making software development worry freeWe offer outstanding sector expertise and premium software consulting and development services. Rather than leasing developers from an agency, our clients de-risk their development and stay worry-free by outsourcing work to us.
read more...




Saving you time and moneyOur rates are highly competitive and, by outsourcing projects with us, you get the advantages of reduced management overheads, better cost control, formal methodologies, quality  deliverables and meeting your project milestones.
read more...












Contact Us!
Got a question or a query? If you need more information on our skills and capabilities, need an idea about resource availability or just want a rough estimate on development work that you need completed – here’s your chance to get in touch. There is no obligation and we’re always happy to hear from companies large and small. Whether you’re a start-up looking for advice or a multinational looking for local development expertise just drop us a line and we’ll get right back to you. 










Your Name (required)
 
Your Email (required)
 
Subject
 
Your Message
 

  


This website uses cookies to improve your experience. We'll assume you're ok with this, but you can opt-out if you wish.Accept Read MorePrivacy & Cookies Policy



 
 
























































































































































Power Transmission Products and Solutions - SKF





























 










 Change Location: Group

Web Customer Link
 My SKF: Login
  Logout

 Contact



























Products


Services


Industry solutions


Knowledge Centre


News and Media


Career


About SKF


Investors









Group


Products


Power transmission products and solutions








Products






Power transmission products and solutions















SKF Transmission Belts







Power Transmission Belt Pulley






SKF Transmission Chain






Sprockets






Transmission Bushings and Hubs







Couplings




























Power transmission products and solutions




					SKF Power Transmission is a product line that provides a complete range of components including high quality belts, chains, couplings, pulleys, sprockets, bushings and hubs.


Required in virtually every industry, our power transmission solutions enable processes to run by connecting moving parts in machinery.


Regardless of whether the challenge lies in designing equipment that increases plant efficiency or to improve overall profitability, SKF's experience and expertise can help you meet your goals.


At SKF, we are dedicated to helping your business reduce the total cost of ownership in the long-run (fig. 1).


By choosing SKF Power Transmission products, you are investing in high quality, high performance solutions that enable your machinery to run more efficiently and increase its Mean Time Between Failure / Repair (MTBF/R).


This translates into substantial savings on ownership costs as you enjoy longer operating life, reduced maintenance of equipment and better Return on Investment (ROI).

				

















Belts






Pulleys






Chains






Sprockets






Bushings and hubs






Couplings












Find a distributor







Select location *
Albania
Algeria
Angola
Argentina
Armenia
Australia
Austria
Azerbaijan
Bahrain
Bangladesh
Belarus
Belgium
Belize
Benin
Bhutan
Bolivia, Plurinational State of
Bosnia and Herzegovina
Botswana
Brazil
Brunei Darussalam
Bulgaria
Burkina Faso
Cambodia
Cameroon
Canada
Chile
China
Colombia
Congo
Congo, Democratic Republic of
Costa Rica
Cote D'Ivoire
Croatia
Cuba
Curacao
Cyprus
Czech Republic
Denmark
Dominican Republic
Ecuador
Egypt
El Salvador
Estonia
Ethiopia
Faroe Islands
Finland
France
French Guiana
French Polynesia
Gabon
Georgia
Germany
Ghana
Greece
Guadeloupe
Guatemala
Guinea
Guyana
Honduras
Hungary
Iceland
India
Indonesia
Iran, Islamic Republic of
Iraq
Ireland
Israel
Italy
Jamaica
Japan
Jersey
Jordan
Kazakhstan
Kenya
Korea, Republic of
Kuwait
Kyrgyzstan
Latvia
Lebanon
Liberia
Libya
Lithuania
Luxembourg
Macedonia
Madagascar
Malawi
Malaysia
Mali
Malta
Martinique
Mauritius
Mayotte
Mexico
Moldova, Republic of
Mongolia
Montenegro
Morocco
Mozambique
Myanmar
Namibia
Nepal
Netherlands
New Caledonia
New Zealand
Nicaragua
Niger
Nigeria
Norway
Oman
Pakistan
Panama
Papua New Guinea
Paraguay
Peru
Philippines
Poland
Portugal
Puerto Rico
Qatar
Romania
Russian Federation
Rwanda
Réunion
Saudi Arabia
Senegal
Serbia
Sierra Leone
Singapore
Slovakia
Slovenia
South Africa
Spain
Sri Lanka
Sudan
Suriname
Swaziland
Sweden
Switzerland
Syrian arabic republic
Taiwan
Tanzania, United Republic of
Thailand
Togo
Trinidad and Tobago
Tunisia
Turkey
Uganda
Ukraine
United Arab Emirates
United Kingdom
United States
Uruguay
Venezuela
Vietnam
Yemen
Zambia
Zimbabwe




State





City







Product category




Distributor category *














Contact us
for more information








The more we know about your request, the better we can connect you to the right person or information.

Type of request*

You must select a type of request
CareerContact automotive supportContact engineering supportContact industrial salesContact technical supportFind a distributorRequest literatureRequest trainingSubmit comments about the website



Your message*



Your first name*



Your last name*



Email address*



Phone number (with country code)*



Company name*



Address




ZIP code*





Location*

Select location 
AfghanistanAland IslandsAlbaniaAlgeriaAmerican SamoaAndorraAngolaAnguillaAntarcticaAntigua and BarbudaArgentinaArmeniaArubaAustraliaAustriaAzerbaijanBahamasBahrainBangladeshBarbadosBelarusBelgiumBelizeBeninBermudaBhutanBolivia, Plurinational State ofBonaire, Sint Eustatius and SabaBosnia and HerzegovinaBotswanaBouvet IslandBrazilBritish Indian Ocean TerritoryBrunei DarussalamBulgariaBurkina FasoBurundiCambodiaCameroonCanadaCape VerdeCayman IslandsCentral African RepublicChadChileChinaChristmas IslandCocos (Keeling) IslandsColombiaComorosCongoCongo, Democratic Republic ofCook IslandsCosta RicaCote D'IvoireCroatiaCubaCuracaoCyprusCzech RepublicDenmarkDjiboutiDominicaDominican RepublicEcuadorEgyptEl SalvadorEquatorial GuineaEritreaEstoniaEthiopiaFalkland Islands (Malvinas)Faroe IslandsFijiFinlandFranceFrench GuianaFrench PolynesiaFrench Southern TerritoriesGabonGambiaGeorgiaGermanyGhanaGibraltarGreeceGreenlandGrenadaGuadeloupeGuamGuatemalaGuernseyGuineaGuinea-BissauGuyanaHaitiHeard Island and McDonald IslandsHoly See (Vatican City State)HondurasHong KongHungaryIcelandIndiaIndonesiaIran, Islamic Republic ofIraqIrelandIsle of ManIsraelItalyJamaicaJapanJerseyJordanKazakhstanKenyaKiribatiKorea, Democratic People's Republic ofKorea, Republic ofKuwaitKyrgyzstanLao People's Democratic RepublicLatviaLebanonLesothoLiberiaLibyaLiechtensteinLithuaniaLuxembourgMacaoMacedoniaMadagascarMalawiMalaysiaMaldivesMaliMaltaMarshall IslandsMartiniqueMauritaniaMauritiusMayotteMexicoMicronesia, Federated States ofMoldova, Republic ofMonacoMongoliaMontenegroMontserratMoroccoMozambiqueMyanmarNamibiaNauruNepalNetherlandsNew CaledoniaNew ZealandNicaraguaNigerNigeriaNiueNorfolk IslandNorthern Mariana IslandsNorwayOmanPakistanPalauPalestinian Territory, OccupiedPanamaPapua New GuineaParaguayPeruPhilippinesPitcairnPolandPortugalPuerto RicoQatarRomaniaRussian FederationRwandaRéunionSaint BarthélemySaint Helena, Ascension and Tristan da CunhaSaint Kitts and NevisSaint LuciaSaint Martin (French part)Saint Pierre and MiquelonSaint Vincent & the GrenadinesSamoaSan MarinoSao Tome and PrincipeSaudi ArabiaSenegalSerbiaSeychellesSierra LeoneSingaporeSint Maarten (Dutch part)SlovakiaSloveniaSolomon IslandsSomaliaSouth AfricaSouth Georgia and the South Sandwich IslandsSouth SudanSpainSri LankaSudanSurinameSvalbard and Jan MayenSwazilandSwedenSwitzerlandSyrian arabic republicTaiwanTajikistanTanzania, United Republic ofThailandTimor-LesteTogoTokelauTongaTrinidad and TobagoTunisiaTurkeyTurkmenistanTurks and Caicos IslandsTuvaluUgandaUkraineUnited Arab EmiratesUnited KingdomUnited StatesUnited States, minor outlying islandsUruguayUzbekistanVanuatuVenezuelaVietnamVirgin Islands, BritishVirgin Islands, U.S.Wallis and FutunaWestern SaharaYemenZambiaZimbabwe





Region*

Select region



State*

Select state



City*






I have read the Privacy policy and agree to it
							













Related information


Related documents



SKF Power Transmission products
(6.6 MB)



Success stories



SKF Belts enable blowers to run smoothly

SKF customises coupling weighing more that 2,000kg

SKF FX Bushings demonstrates superior quality and performance

SKF Xtra Power Belts increase uptime fan belt drive

SKF Chains and Sprockets significantly reduce downtime and costs by maintenance 40%





Engineering tools



Power Transmission products





Belt Calculator

Belt Drive Design Calculations tool

Power Transmission Products catalogue



















Print this page


Share


Share this page




Myspace
Twitter
Google
Blogger


Friendster
Reddit
Stumbleupon
Email


Delicious
LinkedIn
Facebook
More ...











RSS feeds
Accessibility help
Mobile
App store

























My SKF



									        Login
									    


									        Register
									    


									        Forgot password?
									    




How can we help?




I would like to know...
Find detailed product informationHave someone contact me fastReport a defect or make comments about the websiteIncrease the website font sizeFind the SKF website in another language

I would like to know...







You are here > GroupChoose locationAfricaAfriqueShqipëriArgentinaAustralia & New ZealandÖsterreichBeneluxBosna i HercegovinaBrasilБългарияCanada
							(en)
						Canada
							(fr)
						CaribbeanChile中国ChinaHrvatskaČeská republikaDanmarkEestiSuomiFranceDeutschlandΕλλάδαGroupMagyarországIndiaIndonesia
							(en)
						Indonesia
							(id)
						IsraelItalia日本한국LatvijaLietuvaМакедонијаMalaysiaMaltaMéxicoMiddle EastNorgePakistanPhilippinesPolskaPortugalRomâniaРоссияСрбија и Црна ГораSingaporeSlovenská republikaSlovenijaEspañaSverigeSchweizSuisse台灣ไทยTürkiyeУкраїнаUnited KingdomUnited StatesUruguayVenezuelaVietnamViệt Nam




Follow SKF
FacebookYouTubeLinkedInTwitterGoogle+InstagramTumblr










Products



											        Actuation systems
											    


											        Bearings, units & housings
											    


											        Condition monitoring
											    


											        Coupling systems
											    


											        Lubrication solutions
											    


											        Linear motion
											    


											        Magnetic systems
											    


											        Maintenance products
											    


											        Power transmission
											    


											        Seals
											    


											        Test & measurement equipment
											    


											        Vehicle aftermarket
											    


Services



											        Asset management services
											    


											        Customer training
											    


											        Engineering consultancy
											    


											        Logistics
											    


											        Mechanical maintenance
											    


											        Remanufacturing & maintenance services
											    


											        Service contracts
											    




Industry solutions



											        Aerospace
											    


											        Agriculture
											    


											        Automation
											    


											        Cars & light trucks
											    


											        Compressors
											    


											        Construction
											    


											        Electric motors
											    


											        Food & beverage
											    


											        Home Appliances
											    


											        Industrial fans
											    


											        Industrial pumps
											    


											        Industrial transmissions
											    


											        Machine tool
											    


											        Marine
											    


											        Material handling
											    


											        Medical & health care
											    


											        Metals
											    


											        Mining & mineral processing
											    


											        Ocean energy
											    


											        Oil & gas
											    


											        Portable power tools
											    


											        Power generation
											    


											        Pulp & paper
											    


											        Racing
											    


											        Railways
											    


											        Skates
											    


											        Trucks, trailers & buses
											    


											        Two & three wheelers
											    


											        Wind energy
											    




Knowledge Centre



											        Library
											    


											        SKF Mobile Apps
											    


											        Engineering tools
											    


											        Webinars
											    


											        Bookstore
											    


											        E-learning
											    


											        Rich media
											    


											        Conferences
											    


											        Archive
											    


											        Forum and Blog
											    


											        Valued Partner code
											    


News and Media



											        News search
											    


											        Events search
											    


											        In Focus
											    


											        Evolution magazine
											    


											        Media download
											    


											        Press contacts
											    


											        Investor relations
											    




Career



												        Job openings
												    


												        Professional
												    


												        Graduates
												    


												        Students
												    


												        What we do
												    


About SKF



												        Find a distributor
												    


												        SKF locations
												    


												        Organization
												    


												        Let’s Talk
												    


												        What Engineers say
												    


												        Research and development
												    


												        Supplier Portal
												    







© Copyright
Terms & Conditions
Privacy policy
Site ownership
Cookies
General Conditions of Sales

































GroupWise | Micro Focus








































 








GroupWise



Overview
Features
Tech Specs
Resources
How to Buy
Trial Download











Home





Products





GroupWise



			Overview











Modern Email and Business Communication
Email, instant messaging, and scheduling for today’s mobile world.

Download your free trial












			    		GroupWise is also a part of Open Workgroup Suite.
			    	

Learn more









											OVERVIEW
									



Micro Focus GroupWise® (formerly Novell® GroupWise) is a complete collaboration software solution that provides email, scheduling, instant messaging, task management, contact management, and document management functions.










Flash Point Paper
Effective Communication, Lower Ownership Costs Getting More Value from Email

View now ›












Top Reasons
Top Ten Things You Lose Moving From GroupWise to Exchange

View now ›











Stay on track: Calendars, scheduling, task management, and email keep you organized.

Keep in touch: GroupWise offers emails, IMs, call-back reminders, notes, and more.

Accomplish more: Set follow-ups, tasks with due dates, and request replies all through email.

Built for today: Dynamic interfaces support multiple desktop and mobile platforms.










						HIGHLIGHTS
					






What's New in GroupWise 2014 R2 SP2?
Wondering what's new in the latest version of GroupWise? Quickly discover new features and enhancements you need to know about when upgrading to the latest version.
Read more ›











Wander while you work
GroupWise gives employees robust email, calendaring, task management, and contact management tools wherever they wander. The same goes for admins, who get streamlined and web-based administration to let them monitor, manage, and make things happen on the go.
Read more ›











Dynamic flexibility
What good is power without flexibility? GroupWise gives end users a flexible, dynamic interface that works the way they want to work—and the freedom to make (or change) decisions at will. It also supports the platforms and devices admins need, and even flexes itself to work with Active Directory and Microsoft Exchange.











Built for today
GroupWise provides classic email and calendaring features in a modern and efficient package. It runs on the latest data center technology, supports the latest devices, and sports a user interface that dynamically adjusts to deliver just what you need, right when you need it. Best of all, it keeps your email—and the critical business data that traverses it—firmly within IT's control.












View all features ›
See the latest updates and versions ›
Start your free trial today








Sign up for updates









Select your country
Afghanistan
Albania
Algeria
American Samoa
Andorra
Angola
Anguilla
Antarctica
Antigua and Barbuda
Argentina
Armenia
Aruba
Australia
Austria
Azerbaijan
Bahamas
Bahrain
Bangladesh
Barbados
Belarus
Belgium
Belize
Benin
Bermuda
Bhutan
Bolivia
Bosnia and Herzegovina
Botswana
Bouvet Island
Brazil
British Indian Ocean Territory
Brunei Darussalam
Bulgaria
Burkina Faso
Burundi
Cambodia
Cameroon
Canada
Cape Verde
Cayman Islands
Central African Republic
Chad
Chile
China
Christmas Island
Cocos (Keeling) Islands
Colombia
Comoros
Congo
Congo, the Democratic Republic of the
Cook Islands
Costa Rica
Cote d'Ivoire
Croatia
Cyprus
Czech Republic
Denmark
Djibouti
Dominica
Dominican Republic
Ecuador
Egypt
El Salvador
Equatorial Guinea
Eritrea
Estonia
Ethiopia
Falkland Islands (Malvinas)
Faroe Islands
Fiji Islands
Finland
France
French Guiana
French Polynesia
French Southern Territories
Gabon
Gambia
Georgia
Germany
Ghana
Gibraltar
Greece
Greenland
Grenada
Guadeloupe
Guam
Guatemala
Guinea
Guinea-Bissau
Guyana
Haiti
Heard Island and McDonald Islands
Honduras
Hong Kong
Hungary
Iceland
India
Indonesia
Iraq
Ireland
Israel
Italy
Jamaica
Japan
Jordan
Kazakhstan
Kenya
Kiribati
Korea, Republic of
Kuwait
Kyrgyzstan
Lao People's Democratic Republic
Latvia
Lebanon
Lesotho
Liberia
Libyan Arab Jamahiriya
Liechtenstein
Lithuania
Luxembourg
Macao
Macedonia
Madagascar
Malawi
Malaysia
Maldives
Mali
Malta
Marshall Islands
Martinique
Mauritania
Mauritius
Mayotte
Mexico
Micronesia, Federated States of
Moldova, Republic of
Monaco
Mongolia
Montserrat
Morocco
Mozambique
Myanmar
Namibia
Nauru
Nepal
Netherlands
Netherlands Antilles
New Caledonia
New Zealand
Nicaragua
Niger
Nigeria
Niue
Norfolk Island
Northern Mariana Islands
Norway
Oman
Pakistan
Palau
Palestinian Territory, Occupied
Panama
Papua New Guinea
Paraguay
Peru
Philippines
Pitcairn
Poland
Portugal
Puerto Rico
Qatar
Reunion
Romania
Russia
Rwanda
Saint Helena
Saint Kitts and Nevis
Saint Lucia
Saint Pierre and Miquelon
Saint Vincent and the Grenadines
Samoa
San Marino
Sao Tome and Principe
Saudi Arabia
Senegal
Serbia and Montenegro
Seychelles
Sierra Leone
Singapore
Slovakia
Slovenia
Solomon Islands
Somalia
South Africa
South Georgia and the South Sandwich Islands
Spain
Sri Lanka
Suriname
Svalbard and Jan Mayen
Swaziland
Sweden
Switzerland
Taiwan, Republic of China
Tajikistan
Tanzania
Thailand
Timor-Leste
Togo
Tokelau
Tonga
Trinidad and Tobago
Tunisia
Turkey
Turkmenistan
Turks and Caicos Islands
Tuvalu
Uganda
Ukraine
United Arab Emirates
United Kingdom
United States
United States Minor Outlying Islands
Uruguay
Uzbekistan
Vanuatu
Vatican City State
Venezuela
Vietnam
Virgin Islands, British
Virgin Islands, U.S.
Wallis and Futuna
Western Sahara
Yemen
Zambia
Zimbabwe















CUSTOMER STORIES




GroupWise gives top officials secure smartphone access to email and calendars, from any location.
Read full story ›






GroupWise helped this group of 18 local school districts improve their student programs and their staff curriculum development.
Read full story ›






Rapidly expanding Polish furniture company offers its employees cost-effective, secure online collaboration.
Read full story ›





See all customer success stories ›







											RESOURCES
									










Flash Point Paper
Effective Communication, Lower Ownership Costs Getting More Value from Email
View now ›














White Paper
The Real Cost and Business Disruption of Migrating from GroupWise To Exchange Business White Paper
View now ›















Top Reasons
Top Ten Things You Lose Moving from GroupWise to Gmail
View now ›







See all resources ›







                  RELATED PRODUCTS
              





Vibe

Collaborate more easily by storing, organizing, and sharing all information related to a specific project in a secure, online workspace.






Retain

Securely archive multi-platform email, appointments, files, and attachments, including Exchange, Lotus Notes, and GroupWise. Quickly access, search, and audit archived communication data.







Secure Gateway

Inbound and outbound protection for your company's enterprise network and messaging system, including antivirus, anti-spam, cybercrime protection, DDOS protection, and porn blocking with built-in image analysis.






GroupWise Disaster Recovery

A backup and disaster recovery tool for GroupWise that ensures your critical email system data is always current and available.








GroupWise Mailbox Management

Manage GroupWise mailboxes from a single intuitive administrative tool.






GroupWise Reporting & Monitoring

Evaluate the health of GroupWise systems with customizable monitoring and reporting tools.












Get the most out of our products

Visit our support & services ›
Training ›
Visit the Micro Focus forums ›






Already a customer?

Technical resources ›
Trial downloads ›
My support ›




















The translated version of this page is coming soon. In the meantime, content will appear in standard North American English.
 Don't show this message again











































